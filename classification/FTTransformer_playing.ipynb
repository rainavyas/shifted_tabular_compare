{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtdl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.543321e+09</td>\n",
       "      <td>26.968800</td>\n",
       "      <td>-99.248901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-17.526443</td>\n",
       "      <td>14.613571</td>\n",
       "      <td>754.263405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.600006</td>\n",
       "      <td>-2.750006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.538776e+09</td>\n",
       "      <td>29.374201</td>\n",
       "      <td>-100.927002</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>297.0</td>\n",
       "      <td>41.531032</td>\n",
       "      <td>26.992143</td>\n",
       "      <td>733.117168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.600006</td>\n",
       "      <td>17.950006</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552115e+09</td>\n",
       "      <td>22.149599</td>\n",
       "      <td>113.592003</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43.916531</td>\n",
       "      <td>18.842143</td>\n",
       "      <td>761.571076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233978</td>\n",
       "      <td>21.450006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.549566e+09</td>\n",
       "      <td>34.678699</td>\n",
       "      <td>-86.684799</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.240955</td>\n",
       "      <td>8.303571</td>\n",
       "      <td>747.524910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>16.150018</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.552910e+09</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>41.966667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.394660</td>\n",
       "      <td>6.451429</td>\n",
       "      <td>753.168113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>3.150018</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1.543321e+09      26.968800      -99.248901               2.0   \n",
       "1  1.538776e+09      29.374201     -100.927002              31.0   \n",
       "2  1.552115e+09      22.149599      113.592003              17.0   \n",
       "3  1.549566e+09      34.678699      -86.684799              24.0   \n",
       "4  1.552910e+09      46.066667       41.966667               9.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0              0.0             dry                  127.0     -17.526443   \n",
       "1             20.0  mild temperate                  297.0      41.531032   \n",
       "2             10.0  mild temperate                   -1.0      43.916531   \n",
       "3             20.0  mild temperate                  193.0      40.240955   \n",
       "4             20.0             dry                   90.0      30.394660   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            14.613571        754.263405  ...                0.0   \n",
       "1            26.992143        733.117168  ...                0.0   \n",
       "2            18.842143        761.571076  ...                0.0   \n",
       "3             8.303571        747.524910  ...                0.0   \n",
       "4             6.451429        753.168113  ...                0.0   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0             -2.600006             -2.750006   \n",
       "1                0.0             -0.600006             17.950006   \n",
       "2                0.0             -0.233978             21.450006   \n",
       "3                0.0              0.059448             16.150018   \n",
       "4                0.0              0.400024              3.150018   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              0.0                              0.0  \n",
       "1                            -12.0                             11.0  \n",
       "2                              1.0                              8.0  \n",
       "3                            -58.0                             41.0  \n",
       "4                             18.0                             92.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "train_path = 'data/train.csv'\n",
    "dev_in_path = 'data/dev_in.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3129592\n",
      "2965544\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN in training data\n",
    "print(len(df_train))\n",
    "df_train = df_train.dropna()\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539162000</td>\n",
       "      <td>-40.350000</td>\n",
       "      <td>-9.880000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>tropical</td>\n",
       "      <td>-843.0</td>\n",
       "      <td>31.782490</td>\n",
       "      <td>10.070714</td>\n",
       "      <td>765.631228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505035</td>\n",
       "      <td>2.647577</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1545006600</td>\n",
       "      <td>53.421299</td>\n",
       "      <td>-6.270070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-59.691521</td>\n",
       "      <td>7.005000</td>\n",
       "      <td>752.897615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400024</td>\n",
       "      <td>1.249994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540094400</td>\n",
       "      <td>-19.757700</td>\n",
       "      <td>63.361000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>dry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.250889</td>\n",
       "      <td>23.327143</td>\n",
       "      <td>763.115016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>21.050012</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1552611600</td>\n",
       "      <td>35.245899</td>\n",
       "      <td>47.009201</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>-23.755615</td>\n",
       "      <td>3.109286</td>\n",
       "      <td>609.419333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69672</td>\n",
       "      <td>5.1653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.349982</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1545631200</td>\n",
       "      <td>26.633333</td>\n",
       "      <td>118.150000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>210.0</td>\n",
       "      <td>33.040438</td>\n",
       "      <td>12.172143</td>\n",
       "      <td>734.678037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102081</td>\n",
       "      <td>11.513879</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1539162000     -40.350000       -9.880000              11.0   \n",
       "1  1545006600      53.421299       -6.270070               4.0   \n",
       "2  1540094400     -19.757700       63.361000              26.0   \n",
       "3  1552611600      35.245899       47.009201               5.0   \n",
       "4  1545631200      26.633333      118.150000              14.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0               10        tropical                 -843.0      31.782490   \n",
       "1               10  mild temperate                   67.0     -59.691521   \n",
       "2               10             dry                    6.0      35.250889   \n",
       "3               10  mild temperate                 1390.0     -23.755615   \n",
       "4               20  mild temperate                  210.0      33.040438   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            10.070714        765.631228  ...            0.00000   \n",
       "1             7.005000        752.897615  ...            0.00000   \n",
       "2            23.327143        763.115016  ...            0.00000   \n",
       "3             3.109286        609.419333  ...            1.69672   \n",
       "4            12.172143        734.678037  ...            0.00000   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0             0.0000                0.0           0.000000                0.0   \n",
       "1             0.0000                0.0           0.000000                0.0   \n",
       "2             0.0000                0.0           0.000000                0.0   \n",
       "3             5.1653                0.0           0.000049                0.0   \n",
       "4             0.0000                0.0           0.000000                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0              0.505035              2.647577   \n",
       "1                0.0             -0.400024              1.249994   \n",
       "2                0.0              0.100006             21.050012   \n",
       "3                0.0             -1.500000             -0.349982   \n",
       "4                0.0              0.102081             11.513879   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              2.0                              2.0  \n",
       "1                              0.0                              0.0  \n",
       "2                             -1.0                              1.0  \n",
       "3                            -12.0                             81.0  \n",
       "4                            -15.0                             83.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_in = pd.read_csv(dev_in_path)\n",
    "df_dev_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN with 0 for dev_in data\n",
    "print(len(df_dev_in))\n",
    "df_dev_in = df_dev_in.fillna(0)\n",
    "print(len(df_dev_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1850eddf300>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Seed\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess into tensors\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_lab_to_ind(data_df):\n",
    "    '''\n",
    "    Prepare a label to index map\n",
    "    '''\n",
    "    y_fact = set(list(data_df['fact_cwsm_class']))\n",
    "    lab_to_ind = {}\n",
    "    for i, lab in enumerate(y_fact):\n",
    "        lab_to_ind[lab] = i\n",
    "    return lab_to_ind\n",
    "\n",
    "lab_to_ind = get_lab_to_ind(df_train)\n",
    "batch_size = 256\n",
    "\n",
    "# Train\n",
    "X_train = torch.FloatTensor(np.asarray(df_train.iloc[:,6:]))\n",
    "y_train = np.asarray(df_train['fact_cwsm_class'])\n",
    "y_train = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_train]))\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Dev in\n",
    "X_dev_in = torch.FloatTensor(np.asarray(df_dev_in.iloc[:,6:]))\n",
    "y_dev_in = df_dev_in['fact_cwsm_class']\n",
    "y_dev_in = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_dev_in]))\n",
    "\n",
    "dev_in_ds = TensorDataset(X_dev_in, y_dev_in)\n",
    "dev_in_dl = DataLoader(dev_in_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA found\n"
     ]
    }
   ],
   "source": [
    "# Get the device\n",
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Got CUDA!\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"No CUDA found\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTTransformer(\n",
       "  (feature_tokenizer): FeatureTokenizer(\n",
       "    (num_tokenizer): NumericalFeatureTokenizer()\n",
       "  )\n",
       "  (cls_token): CLSToken()\n",
       "  (transformer): Transformer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (head): Head(\n",
       "      (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): ReLU()\n",
       "      (linear): Linear(in_features=192, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Feature Transformer Model\n",
    "\n",
    "model = rtdl.FTTransformer.make_default(\n",
    "    n_num_features=X_train.shape[1],\n",
    "    cat_cardinalities=None,\n",
    "    last_layer_query_idx=[-1],\n",
    "    d_out=len(lab_to_ind)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "\n",
    "# These params don't need to be set as we will use a default optimizer\n",
    "# lr = 0.01\n",
    "# weight_decay = 0.9\n",
    "\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters(), lr=lr,\n",
    "                          weight_decay=weight_decay)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function criterion\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline to apply model\n",
    "def apply_model(model, x_num, x_cat=None):\n",
    "    '''\n",
    "    FTTransformer expects numerical and categorical inputs separately\n",
    "    '''\n",
    "    return model(x_num, x_cat) if isinstance(model, rtdl.FTTransformer) else model(x_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Function\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy_topk(output, target, k=1):\n",
    "    \"\"\"Computes the topk accuracy\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = torch.topk(output, k=k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "    res_total = 0\n",
    "    for curr_k in range(k):\n",
    "      curr_ind = pred[:,curr_k]\n",
    "      num_eq = torch.eq(curr_ind, target).sum()\n",
    "      acc = num_eq/len(output)\n",
    "      res_total += acc\n",
    "    return res_total*100\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, device, print_freq=5):\n",
    "    '''\n",
    "    Run one train epoch\n",
    "    '''\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (x, target) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = apply_model(model, x)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # Backward pass and update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy_topk(logits.data, target)\n",
    "        accs.update(acc.item(), x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                    'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                    'Accuracy {prec.val:.3f} ({prec.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader),\n",
    "                      loss=losses, prec=accs))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(val_loader, model, criterion, device):\n",
    "    '''\n",
    "    Run evaluation\n",
    "    '''\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for i, (x, target) in enumerate(val_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = apply_model(model, x)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy_topk(logits.data, target)\n",
    "        accs.update(acc.item(), x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "    print('Dev in\\t Loss ({loss.avg:.4f})\\t'\n",
    "            'Accuracy ({prec.avg:.3f})\\n'.format(\n",
    "              loss=losses, prec=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-04\n",
      "Epoch: [0][0/11585]\tLoss 2.4380 (2.4380)\tAccuracy 1.562 (1.562)\n",
      "Epoch: [0][5/11585]\tLoss 1.9627 (2.1928)\tAccuracy 28.125 (17.969)\n",
      "Epoch: [0][10/11585]\tLoss 1.6063 (1.9975)\tAccuracy 35.938 (25.107)\n",
      "Epoch: [0][15/11585]\tLoss 1.5470 (1.8667)\tAccuracy 41.016 (28.467)\n",
      "Epoch: [0][20/11585]\tLoss 1.4440 (1.7773)\tAccuracy 36.719 (30.450)\n",
      "Epoch: [0][25/11585]\tLoss 1.3629 (1.7122)\tAccuracy 41.797 (31.956)\n",
      "Epoch: [0][30/11585]\tLoss 1.3858 (1.6633)\tAccuracy 39.453 (32.976)\n",
      "Epoch: [0][35/11585]\tLoss 1.5077 (1.6272)\tAccuracy 33.203 (33.474)\n",
      "Epoch: [0][40/11585]\tLoss 1.4634 (1.6019)\tAccuracy 38.672 (33.851)\n",
      "Epoch: [0][45/11585]\tLoss 1.3368 (1.5797)\tAccuracy 35.938 (34.035)\n",
      "Epoch: [0][50/11585]\tLoss 1.3595 (1.5578)\tAccuracy 35.938 (34.176)\n",
      "Epoch: [0][55/11585]\tLoss 1.3092 (1.5421)\tAccuracy 39.062 (34.570)\n",
      "Epoch: [0][60/11585]\tLoss 1.4010 (1.5287)\tAccuracy 39.062 (34.849)\n",
      "Epoch: [0][65/11585]\tLoss 1.3414 (1.5192)\tAccuracy 38.672 (34.943)\n",
      "Epoch: [0][70/11585]\tLoss 1.3333 (1.5076)\tAccuracy 39.453 (35.129)\n",
      "Epoch: [0][75/11585]\tLoss 1.3680 (1.4996)\tAccuracy 37.500 (35.331)\n",
      "Epoch: [0][80/11585]\tLoss 1.4302 (1.4936)\tAccuracy 36.328 (35.532)\n",
      "Epoch: [0][85/11585]\tLoss 1.3285 (1.4852)\tAccuracy 42.969 (35.651)\n",
      "Epoch: [0][90/11585]\tLoss 1.4347 (1.4810)\tAccuracy 33.594 (35.641)\n",
      "Epoch: [0][95/11585]\tLoss 1.3901 (1.4752)\tAccuracy 42.969 (35.787)\n",
      "Epoch: [0][100/11585]\tLoss 1.3455 (1.4701)\tAccuracy 39.062 (35.787)\n",
      "Epoch: [0][105/11585]\tLoss 1.3442 (1.4653)\tAccuracy 38.281 (35.867)\n",
      "Epoch: [0][110/11585]\tLoss 1.4013 (1.4613)\tAccuracy 39.844 (35.959)\n",
      "Epoch: [0][115/11585]\tLoss 1.4459 (1.4560)\tAccuracy 35.156 (36.065)\n",
      "Epoch: [0][120/11585]\tLoss 1.3428 (1.4513)\tAccuracy 41.406 (36.202)\n",
      "Epoch: [0][125/11585]\tLoss 1.3679 (1.4485)\tAccuracy 39.453 (36.275)\n",
      "Epoch: [0][130/11585]\tLoss 1.3502 (1.4448)\tAccuracy 39.453 (36.292)\n",
      "Epoch: [0][135/11585]\tLoss 1.3601 (1.4415)\tAccuracy 33.984 (36.311)\n",
      "Epoch: [0][140/11585]\tLoss 1.3608 (1.4383)\tAccuracy 41.016 (36.328)\n",
      "Epoch: [0][145/11585]\tLoss 1.3671 (1.4357)\tAccuracy 38.281 (36.400)\n",
      "Epoch: [0][150/11585]\tLoss 1.2762 (1.4325)\tAccuracy 38.672 (36.437)\n",
      "Epoch: [0][155/11585]\tLoss 1.4078 (1.4299)\tAccuracy 36.328 (36.421)\n",
      "Epoch: [0][160/11585]\tLoss 1.3740 (1.4276)\tAccuracy 40.625 (36.457)\n",
      "Epoch: [0][165/11585]\tLoss 1.2921 (1.4248)\tAccuracy 42.188 (36.545)\n",
      "Epoch: [0][170/11585]\tLoss 1.3693 (1.4229)\tAccuracy 37.891 (36.611)\n",
      "Epoch: [0][175/11585]\tLoss 1.3630 (1.4203)\tAccuracy 38.672 (36.685)\n",
      "Epoch: [0][180/11585]\tLoss 1.3405 (1.4191)\tAccuracy 32.422 (36.658)\n",
      "Epoch: [0][185/11585]\tLoss 1.3883 (1.4175)\tAccuracy 37.109 (36.628)\n",
      "Epoch: [0][190/11585]\tLoss 1.4047 (1.4159)\tAccuracy 31.641 (36.596)\n",
      "Epoch: [0][195/11585]\tLoss 1.3995 (1.4141)\tAccuracy 42.578 (36.633)\n",
      "Epoch: [0][200/11585]\tLoss 1.2636 (1.4117)\tAccuracy 40.234 (36.666)\n",
      "Epoch: [0][205/11585]\tLoss 1.4446 (1.4108)\tAccuracy 33.203 (36.654)\n",
      "Epoch: [0][210/11585]\tLoss 1.3654 (1.4098)\tAccuracy 33.984 (36.680)\n",
      "Epoch: [0][215/11585]\tLoss 1.3915 (1.4083)\tAccuracy 34.375 (36.704)\n",
      "Epoch: [0][220/11585]\tLoss 1.3315 (1.4066)\tAccuracy 38.672 (36.713)\n",
      "Epoch: [0][225/11585]\tLoss 1.3396 (1.4062)\tAccuracy 37.109 (36.681)\n",
      "Epoch: [0][230/11585]\tLoss 1.3289 (1.4054)\tAccuracy 39.062 (36.670)\n",
      "Epoch: [0][235/11585]\tLoss 1.4967 (1.4046)\tAccuracy 32.812 (36.684)\n",
      "Epoch: [0][240/11585]\tLoss 1.3417 (1.4042)\tAccuracy 33.984 (36.719)\n",
      "Epoch: [0][245/11585]\tLoss 1.4190 (1.4032)\tAccuracy 32.812 (36.736)\n",
      "Epoch: [0][250/11585]\tLoss 1.3622 (1.4024)\tAccuracy 35.938 (36.720)\n",
      "Epoch: [0][255/11585]\tLoss 1.3240 (1.4010)\tAccuracy 39.844 (36.777)\n",
      "Epoch: [0][260/11585]\tLoss 1.3147 (1.4004)\tAccuracy 41.797 (36.827)\n",
      "Epoch: [0][265/11585]\tLoss 1.3416 (1.3992)\tAccuracy 43.750 (36.910)\n",
      "Epoch: [0][270/11585]\tLoss 1.3794 (1.3982)\tAccuracy 33.984 (36.886)\n",
      "Epoch: [0][275/11585]\tLoss 1.3271 (1.3972)\tAccuracy 37.891 (36.908)\n",
      "Epoch: [0][280/11585]\tLoss 1.4223 (1.3969)\tAccuracy 39.453 (36.926)\n",
      "Epoch: [0][285/11585]\tLoss 1.2946 (1.3951)\tAccuracy 38.281 (36.976)\n",
      "Epoch: [0][290/11585]\tLoss 1.3189 (1.3938)\tAccuracy 39.453 (37.001)\n",
      "Epoch: [0][295/11585]\tLoss 1.2987 (1.3935)\tAccuracy 39.062 (37.013)\n",
      "Epoch: [0][300/11585]\tLoss 1.3168 (1.3928)\tAccuracy 42.578 (37.054)\n",
      "Epoch: [0][305/11585]\tLoss 1.2845 (1.3920)\tAccuracy 35.547 (37.046)\n",
      "Epoch: [0][310/11585]\tLoss 1.3856 (1.3917)\tAccuracy 41.797 (37.055)\n",
      "Epoch: [0][315/11585]\tLoss 1.4063 (1.3910)\tAccuracy 37.891 (37.086)\n",
      "Epoch: [0][320/11585]\tLoss 1.2787 (1.3901)\tAccuracy 42.188 (37.114)\n",
      "Epoch: [0][325/11585]\tLoss 1.3860 (1.3899)\tAccuracy 37.500 (37.139)\n",
      "Epoch: [0][330/11585]\tLoss 1.3198 (1.3890)\tAccuracy 40.234 (37.122)\n",
      "Epoch: [0][335/11585]\tLoss 1.2914 (1.3881)\tAccuracy 42.578 (37.164)\n",
      "Epoch: [0][340/11585]\tLoss 1.3220 (1.3872)\tAccuracy 43.359 (37.201)\n",
      "Epoch: [0][345/11585]\tLoss 1.3937 (1.3871)\tAccuracy 32.031 (37.218)\n",
      "Epoch: [0][350/11585]\tLoss 1.3281 (1.3862)\tAccuracy 37.500 (37.228)\n",
      "Epoch: [0][355/11585]\tLoss 1.4110 (1.3859)\tAccuracy 39.062 (37.239)\n",
      "Epoch: [0][360/11585]\tLoss 1.2858 (1.3851)\tAccuracy 37.109 (37.246)\n",
      "Epoch: [0][365/11585]\tLoss 1.3509 (1.3845)\tAccuracy 37.109 (37.269)\n",
      "Epoch: [0][370/11585]\tLoss 1.3286 (1.3839)\tAccuracy 38.672 (37.265)\n",
      "Epoch: [0][375/11585]\tLoss 1.3306 (1.3832)\tAccuracy 36.719 (37.281)\n",
      "Epoch: [0][380/11585]\tLoss 1.2237 (1.3823)\tAccuracy 44.531 (37.303)\n",
      "Epoch: [0][385/11585]\tLoss 1.3280 (1.3816)\tAccuracy 41.016 (37.327)\n",
      "Epoch: [0][390/11585]\tLoss 1.3007 (1.3806)\tAccuracy 39.062 (37.370)\n",
      "Epoch: [0][395/11585]\tLoss 1.2905 (1.3798)\tAccuracy 44.141 (37.379)\n",
      "Epoch: [0][400/11585]\tLoss 1.3760 (1.3796)\tAccuracy 37.891 (37.423)\n",
      "Epoch: [0][405/11585]\tLoss 1.3567 (1.3786)\tAccuracy 43.359 (37.522)\n",
      "Epoch: [0][410/11585]\tLoss 1.3456 (1.3776)\tAccuracy 37.891 (37.569)\n",
      "Epoch: [0][415/11585]\tLoss 1.3438 (1.3766)\tAccuracy 41.406 (37.608)\n",
      "Epoch: [0][420/11585]\tLoss 1.3838 (1.3760)\tAccuracy 47.656 (37.691)\n",
      "Epoch: [0][425/11585]\tLoss 1.2424 (1.3756)\tAccuracy 50.000 (37.801)\n",
      "Epoch: [0][430/11585]\tLoss 1.2794 (1.3744)\tAccuracy 42.578 (37.879)\n",
      "Epoch: [0][435/11585]\tLoss 1.2705 (1.3733)\tAccuracy 41.016 (37.907)\n",
      "Epoch: [0][440/11585]\tLoss 1.2992 (1.3724)\tAccuracy 49.609 (38.021)\n",
      "Epoch: [0][445/11585]\tLoss 1.3138 (1.3712)\tAccuracy 44.922 (38.138)\n",
      "Epoch: [0][450/11585]\tLoss 1.3042 (1.3703)\tAccuracy 43.750 (38.242)\n",
      "Epoch: [0][455/11585]\tLoss 1.3116 (1.3699)\tAccuracy 41.406 (38.266)\n",
      "Epoch: [0][460/11585]\tLoss 1.2429 (1.3690)\tAccuracy 50.000 (38.358)\n",
      "Epoch: [0][465/11585]\tLoss 1.3159 (1.3680)\tAccuracy 53.906 (38.471)\n",
      "Epoch: [0][470/11585]\tLoss 1.1393 (1.3668)\tAccuracy 57.031 (38.592)\n",
      "Epoch: [0][475/11585]\tLoss 1.2860 (1.3658)\tAccuracy 47.266 (38.698)\n",
      "Epoch: [0][480/11585]\tLoss 1.2860 (1.3649)\tAccuracy 49.609 (38.815)\n",
      "Epoch: [0][485/11585]\tLoss 1.2208 (1.3635)\tAccuracy 51.953 (38.932)\n",
      "Epoch: [0][490/11585]\tLoss 1.2723 (1.3623)\tAccuracy 44.141 (39.039)\n",
      "Epoch: [0][495/11585]\tLoss 1.2504 (1.3612)\tAccuracy 49.609 (39.122)\n",
      "Epoch: [0][500/11585]\tLoss 1.2231 (1.3601)\tAccuracy 46.484 (39.202)\n",
      "Epoch: [0][505/11585]\tLoss 1.2058 (1.3587)\tAccuracy 52.344 (39.289)\n",
      "Epoch: [0][510/11585]\tLoss 1.1725 (1.3574)\tAccuracy 49.609 (39.381)\n",
      "Epoch: [0][515/11585]\tLoss 1.3649 (1.3566)\tAccuracy 45.703 (39.461)\n",
      "Epoch: [0][520/11585]\tLoss 1.3046 (1.3559)\tAccuracy 46.875 (39.526)\n",
      "Epoch: [0][525/11585]\tLoss 1.3257 (1.3552)\tAccuracy 48.438 (39.600)\n",
      "Epoch: [0][530/11585]\tLoss 1.3139 (1.3543)\tAccuracy 42.578 (39.675)\n",
      "Epoch: [0][535/11585]\tLoss 1.2049 (1.3531)\tAccuracy 48.438 (39.759)\n",
      "Epoch: [0][540/11585]\tLoss 1.2066 (1.3519)\tAccuracy 48.047 (39.839)\n",
      "Epoch: [0][545/11585]\tLoss 1.2312 (1.3508)\tAccuracy 46.094 (39.897)\n",
      "Epoch: [0][550/11585]\tLoss 1.1979 (1.3497)\tAccuracy 46.094 (39.973)\n",
      "Epoch: [0][555/11585]\tLoss 1.1946 (1.3485)\tAccuracy 51.172 (40.052)\n",
      "Epoch: [0][560/11585]\tLoss 1.0994 (1.3471)\tAccuracy 52.734 (40.131)\n",
      "Epoch: [0][565/11585]\tLoss 1.1633 (1.3461)\tAccuracy 51.562 (40.194)\n",
      "Epoch: [0][570/11585]\tLoss 1.2365 (1.3447)\tAccuracy 49.609 (40.285)\n",
      "Epoch: [0][575/11585]\tLoss 1.2702 (1.3436)\tAccuracy 48.047 (40.363)\n",
      "Epoch: [0][580/11585]\tLoss 1.1754 (1.3424)\tAccuracy 49.609 (40.436)\n",
      "Epoch: [0][585/11585]\tLoss 1.2290 (1.3415)\tAccuracy 52.734 (40.504)\n",
      "Epoch: [0][590/11585]\tLoss 1.2401 (1.3406)\tAccuracy 45.703 (40.550)\n",
      "Epoch: [0][595/11585]\tLoss 1.2118 (1.3394)\tAccuracy 49.219 (40.637)\n",
      "Epoch: [0][600/11585]\tLoss 1.2417 (1.3386)\tAccuracy 50.391 (40.697)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][605/11585]\tLoss 1.1596 (1.3374)\tAccuracy 49.609 (40.774)\n",
      "Epoch: [0][610/11585]\tLoss 1.3196 (1.3367)\tAccuracy 41.797 (40.824)\n",
      "Epoch: [0][615/11585]\tLoss 1.1790 (1.3355)\tAccuracy 48.828 (40.889)\n",
      "Epoch: [0][620/11585]\tLoss 1.1493 (1.3345)\tAccuracy 53.516 (40.963)\n",
      "Epoch: [0][625/11585]\tLoss 1.1708 (1.3333)\tAccuracy 49.609 (41.024)\n",
      "Epoch: [0][630/11585]\tLoss 1.2102 (1.3322)\tAccuracy 51.172 (41.093)\n",
      "Epoch: [0][635/11585]\tLoss 1.2830 (1.3314)\tAccuracy 42.578 (41.126)\n",
      "Epoch: [0][640/11585]\tLoss 1.2079 (1.3303)\tAccuracy 45.312 (41.186)\n",
      "Epoch: [0][645/11585]\tLoss 1.1284 (1.3296)\tAccuracy 52.734 (41.235)\n",
      "Epoch: [0][650/11585]\tLoss 1.2175 (1.3286)\tAccuracy 46.484 (41.297)\n",
      "Epoch: [0][655/11585]\tLoss 1.1639 (1.3276)\tAccuracy 47.656 (41.346)\n",
      "Epoch: [0][660/11585]\tLoss 1.2296 (1.3269)\tAccuracy 52.344 (41.406)\n",
      "Epoch: [0][665/11585]\tLoss 1.1664 (1.3260)\tAccuracy 50.391 (41.453)\n",
      "Epoch: [0][670/11585]\tLoss 1.1722 (1.3251)\tAccuracy 52.344 (41.500)\n",
      "Epoch: [0][675/11585]\tLoss 1.2773 (1.3243)\tAccuracy 49.609 (41.561)\n",
      "Epoch: [0][680/11585]\tLoss 1.1463 (1.3236)\tAccuracy 48.438 (41.597)\n",
      "Epoch: [0][685/11585]\tLoss 1.1053 (1.3226)\tAccuracy 54.297 (41.657)\n",
      "Epoch: [0][690/11585]\tLoss 1.2159 (1.3214)\tAccuracy 49.609 (41.721)\n",
      "Epoch: [0][695/11585]\tLoss 1.2316 (1.3206)\tAccuracy 45.312 (41.754)\n",
      "Epoch: [0][700/11585]\tLoss 1.2072 (1.3199)\tAccuracy 45.312 (41.790)\n",
      "Epoch: [0][705/11585]\tLoss 1.2789 (1.3192)\tAccuracy 50.000 (41.849)\n",
      "Epoch: [0][710/11585]\tLoss 1.2090 (1.3184)\tAccuracy 50.000 (41.899)\n",
      "Epoch: [0][715/11585]\tLoss 1.1375 (1.3174)\tAccuracy 50.391 (41.965)\n",
      "Epoch: [0][720/11585]\tLoss 1.1656 (1.3166)\tAccuracy 51.953 (42.021)\n",
      "Epoch: [0][725/11585]\tLoss 1.2005 (1.3157)\tAccuracy 49.219 (42.087)\n",
      "Epoch: [0][730/11585]\tLoss 1.0994 (1.3148)\tAccuracy 51.562 (42.132)\n",
      "Epoch: [0][735/11585]\tLoss 1.1207 (1.3140)\tAccuracy 55.078 (42.185)\n",
      "Epoch: [0][740/11585]\tLoss 1.2766 (1.3132)\tAccuracy 44.922 (42.222)\n",
      "Epoch: [0][745/11585]\tLoss 1.1356 (1.3124)\tAccuracy 49.609 (42.262)\n",
      "Epoch: [0][750/11585]\tLoss 1.1854 (1.3117)\tAccuracy 46.875 (42.305)\n",
      "Epoch: [0][755/11585]\tLoss 1.1736 (1.3111)\tAccuracy 50.781 (42.353)\n",
      "Epoch: [0][760/11585]\tLoss 1.1798 (1.3101)\tAccuracy 50.781 (42.409)\n",
      "Epoch: [0][765/11585]\tLoss 1.1520 (1.3094)\tAccuracy 47.656 (42.446)\n",
      "Epoch: [0][770/11585]\tLoss 1.1552 (1.3085)\tAccuracy 53.516 (42.499)\n",
      "Epoch: [0][775/11585]\tLoss 1.1748 (1.3077)\tAccuracy 49.219 (42.552)\n",
      "Epoch: [0][780/11585]\tLoss 1.1452 (1.3070)\tAccuracy 51.172 (42.599)\n",
      "Epoch: [0][785/11585]\tLoss 1.1922 (1.3062)\tAccuracy 50.000 (42.647)\n",
      "Epoch: [0][790/11585]\tLoss 1.1832 (1.3054)\tAccuracy 48.047 (42.688)\n",
      "Epoch: [0][795/11585]\tLoss 1.1307 (1.3047)\tAccuracy 51.953 (42.742)\n",
      "Epoch: [0][800/11585]\tLoss 1.2154 (1.3039)\tAccuracy 49.219 (42.784)\n",
      "Epoch: [0][805/11585]\tLoss 1.1746 (1.3031)\tAccuracy 49.219 (42.834)\n",
      "Epoch: [0][810/11585]\tLoss 1.2143 (1.3023)\tAccuracy 50.391 (42.879)\n",
      "Epoch: [0][815/11585]\tLoss 1.2416 (1.3016)\tAccuracy 42.969 (42.917)\n",
      "Epoch: [0][820/11585]\tLoss 1.1247 (1.3008)\tAccuracy 55.078 (42.957)\n",
      "Epoch: [0][825/11585]\tLoss 1.2640 (1.3002)\tAccuracy 47.266 (42.988)\n",
      "Epoch: [0][830/11585]\tLoss 1.1767 (1.2995)\tAccuracy 46.875 (43.022)\n",
      "Epoch: [0][835/11585]\tLoss 1.2193 (1.2990)\tAccuracy 47.656 (43.047)\n",
      "Epoch: [0][840/11585]\tLoss 1.1294 (1.2982)\tAccuracy 51.562 (43.086)\n",
      "Epoch: [0][845/11585]\tLoss 1.1603 (1.2974)\tAccuracy 52.734 (43.135)\n",
      "Epoch: [0][850/11585]\tLoss 1.2259 (1.2967)\tAccuracy 49.219 (43.170)\n",
      "Epoch: [0][855/11585]\tLoss 1.0975 (1.2960)\tAccuracy 54.688 (43.203)\n",
      "Epoch: [0][860/11585]\tLoss 1.3413 (1.2953)\tAccuracy 43.750 (43.236)\n",
      "Epoch: [0][865/11585]\tLoss 1.1027 (1.2944)\tAccuracy 53.516 (43.285)\n",
      "Epoch: [0][870/11585]\tLoss 1.2307 (1.2937)\tAccuracy 50.000 (43.317)\n",
      "Epoch: [0][875/11585]\tLoss 1.1172 (1.2932)\tAccuracy 50.781 (43.344)\n",
      "Epoch: [0][880/11585]\tLoss 1.2396 (1.2925)\tAccuracy 48.438 (43.386)\n",
      "Epoch: [0][885/11585]\tLoss 1.1540 (1.2918)\tAccuracy 49.219 (43.429)\n",
      "Epoch: [0][890/11585]\tLoss 1.1054 (1.2910)\tAccuracy 53.125 (43.469)\n",
      "Epoch: [0][895/11585]\tLoss 1.3067 (1.2904)\tAccuracy 43.750 (43.503)\n",
      "Epoch: [0][900/11585]\tLoss 1.1358 (1.2895)\tAccuracy 50.000 (43.553)\n",
      "Epoch: [0][905/11585]\tLoss 1.1680 (1.2888)\tAccuracy 47.266 (43.593)\n",
      "Epoch: [0][910/11585]\tLoss 1.2267 (1.2883)\tAccuracy 50.781 (43.626)\n",
      "Epoch: [0][915/11585]\tLoss 1.1108 (1.2874)\tAccuracy 53.516 (43.669)\n",
      "Epoch: [0][920/11585]\tLoss 1.1632 (1.2868)\tAccuracy 49.219 (43.711)\n",
      "Epoch: [0][925/11585]\tLoss 1.1456 (1.2861)\tAccuracy 50.000 (43.747)\n",
      "Epoch: [0][930/11585]\tLoss 1.2347 (1.2856)\tAccuracy 46.484 (43.776)\n",
      "Epoch: [0][935/11585]\tLoss 1.1110 (1.2847)\tAccuracy 50.000 (43.821)\n",
      "Epoch: [0][940/11585]\tLoss 1.2269 (1.2842)\tAccuracy 50.000 (43.850)\n",
      "Epoch: [0][945/11585]\tLoss 1.1485 (1.2837)\tAccuracy 50.781 (43.880)\n",
      "Epoch: [0][950/11585]\tLoss 1.1704 (1.2831)\tAccuracy 55.469 (43.914)\n",
      "Epoch: [0][955/11585]\tLoss 1.1090 (1.2824)\tAccuracy 51.562 (43.951)\n",
      "Epoch: [0][960/11585]\tLoss 1.0950 (1.2817)\tAccuracy 50.000 (43.987)\n",
      "Epoch: [0][965/11585]\tLoss 1.1420 (1.2812)\tAccuracy 48.438 (44.016)\n",
      "Epoch: [0][970/11585]\tLoss 1.1928 (1.2807)\tAccuracy 48.828 (44.038)\n",
      "Epoch: [0][975/11585]\tLoss 1.2668 (1.2803)\tAccuracy 43.359 (44.067)\n",
      "Epoch: [0][980/11585]\tLoss 1.1067 (1.2796)\tAccuracy 54.297 (44.095)\n",
      "Epoch: [0][985/11585]\tLoss 1.2064 (1.2790)\tAccuracy 50.000 (44.120)\n",
      "Epoch: [0][990/11585]\tLoss 1.1004 (1.2784)\tAccuracy 49.609 (44.146)\n",
      "Epoch: [0][995/11585]\tLoss 1.1999 (1.2778)\tAccuracy 49.609 (44.181)\n",
      "Epoch: [0][1000/11585]\tLoss 1.2001 (1.2773)\tAccuracy 51.172 (44.205)\n",
      "Epoch: [0][1005/11585]\tLoss 1.2225 (1.2767)\tAccuracy 48.438 (44.221)\n",
      "Epoch: [0][1010/11585]\tLoss 1.1471 (1.2762)\tAccuracy 51.562 (44.256)\n",
      "Epoch: [0][1015/11585]\tLoss 1.1192 (1.2755)\tAccuracy 47.656 (44.283)\n",
      "Epoch: [0][1020/11585]\tLoss 1.2362 (1.2753)\tAccuracy 46.484 (44.297)\n",
      "Epoch: [0][1025/11585]\tLoss 1.1362 (1.2747)\tAccuracy 51.953 (44.325)\n",
      "Epoch: [0][1030/11585]\tLoss 1.1400 (1.2743)\tAccuracy 53.516 (44.351)\n",
      "Epoch: [0][1035/11585]\tLoss 1.1232 (1.2737)\tAccuracy 48.828 (44.378)\n",
      "Epoch: [0][1040/11585]\tLoss 1.1210 (1.2732)\tAccuracy 51.953 (44.401)\n",
      "Epoch: [0][1045/11585]\tLoss 1.1344 (1.2727)\tAccuracy 48.828 (44.420)\n",
      "Epoch: [0][1050/11585]\tLoss 1.2117 (1.2723)\tAccuracy 49.219 (44.439)\n",
      "Epoch: [0][1055/11585]\tLoss 1.1666 (1.2717)\tAccuracy 46.094 (44.460)\n",
      "Epoch: [0][1060/11585]\tLoss 1.1418 (1.2713)\tAccuracy 46.484 (44.484)\n",
      "Epoch: [0][1065/11585]\tLoss 1.1023 (1.2706)\tAccuracy 48.828 (44.507)\n",
      "Epoch: [0][1070/11585]\tLoss 1.1939 (1.2701)\tAccuracy 48.438 (44.533)\n",
      "Epoch: [0][1075/11585]\tLoss 1.1020 (1.2695)\tAccuracy 55.859 (44.572)\n",
      "Epoch: [0][1080/11585]\tLoss 1.1455 (1.2689)\tAccuracy 53.125 (44.597)\n",
      "Epoch: [0][1085/11585]\tLoss 1.2371 (1.2687)\tAccuracy 49.609 (44.622)\n",
      "Epoch: [0][1090/11585]\tLoss 1.1212 (1.2682)\tAccuracy 52.734 (44.641)\n",
      "Epoch: [0][1095/11585]\tLoss 1.1638 (1.2677)\tAccuracy 50.391 (44.653)\n",
      "Epoch: [0][1100/11585]\tLoss 1.1368 (1.2673)\tAccuracy 51.562 (44.672)\n",
      "Epoch: [0][1105/11585]\tLoss 1.1044 (1.2668)\tAccuracy 51.172 (44.695)\n",
      "Epoch: [0][1110/11585]\tLoss 1.1528 (1.2663)\tAccuracy 52.344 (44.719)\n",
      "Epoch: [0][1115/11585]\tLoss 1.2143 (1.2657)\tAccuracy 48.828 (44.743)\n",
      "Epoch: [0][1120/11585]\tLoss 1.1140 (1.2652)\tAccuracy 50.000 (44.768)\n",
      "Epoch: [0][1125/11585]\tLoss 1.1756 (1.2650)\tAccuracy 46.875 (44.783)\n",
      "Epoch: [0][1130/11585]\tLoss 1.1723 (1.2645)\tAccuracy 50.000 (44.811)\n",
      "Epoch: [0][1135/11585]\tLoss 1.1940 (1.2642)\tAccuracy 48.047 (44.826)\n",
      "Epoch: [0][1140/11585]\tLoss 1.2630 (1.2638)\tAccuracy 45.703 (44.844)\n",
      "Epoch: [0][1145/11585]\tLoss 1.1429 (1.2632)\tAccuracy 50.000 (44.871)\n",
      "Epoch: [0][1150/11585]\tLoss 1.1232 (1.2627)\tAccuracy 50.391 (44.898)\n",
      "Epoch: [0][1155/11585]\tLoss 1.1215 (1.2622)\tAccuracy 53.516 (44.928)\n",
      "Epoch: [0][1160/11585]\tLoss 1.2220 (1.2619)\tAccuracy 45.312 (44.939)\n",
      "Epoch: [0][1165/11585]\tLoss 1.1848 (1.2615)\tAccuracy 53.906 (44.964)\n",
      "Epoch: [0][1170/11585]\tLoss 1.1671 (1.2610)\tAccuracy 45.312 (44.982)\n",
      "Epoch: [0][1175/11585]\tLoss 1.0891 (1.2606)\tAccuracy 53.516 (44.998)\n",
      "Epoch: [0][1180/11585]\tLoss 1.2129 (1.2603)\tAccuracy 48.047 (45.013)\n",
      "Epoch: [0][1185/11585]\tLoss 1.1697 (1.2598)\tAccuracy 48.047 (45.035)\n",
      "Epoch: [0][1190/11585]\tLoss 1.1828 (1.2596)\tAccuracy 46.484 (45.053)\n",
      "Epoch: [0][1195/11585]\tLoss 1.1698 (1.2592)\tAccuracy 48.438 (45.065)\n",
      "Epoch: [0][1200/11585]\tLoss 1.1798 (1.2589)\tAccuracy 46.094 (45.076)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][1205/11585]\tLoss 1.1763 (1.2587)\tAccuracy 46.875 (45.088)\n",
      "Epoch: [0][1210/11585]\tLoss 1.2300 (1.2584)\tAccuracy 44.141 (45.095)\n",
      "Epoch: [0][1215/11585]\tLoss 1.1595 (1.2581)\tAccuracy 47.266 (45.105)\n",
      "Epoch: [0][1220/11585]\tLoss 1.1116 (1.2576)\tAccuracy 57.422 (45.134)\n",
      "Epoch: [0][1225/11585]\tLoss 1.2680 (1.2573)\tAccuracy 46.484 (45.155)\n",
      "Epoch: [0][1230/11585]\tLoss 1.1088 (1.2569)\tAccuracy 55.859 (45.170)\n",
      "Epoch: [0][1235/11585]\tLoss 1.1747 (1.2565)\tAccuracy 51.562 (45.186)\n",
      "Epoch: [0][1240/11585]\tLoss 1.1975 (1.2563)\tAccuracy 48.828 (45.194)\n",
      "Epoch: [0][1245/11585]\tLoss 1.1203 (1.2559)\tAccuracy 53.516 (45.219)\n",
      "Epoch: [0][1250/11585]\tLoss 1.1834 (1.2555)\tAccuracy 50.781 (45.245)\n",
      "Epoch: [0][1255/11585]\tLoss 1.1972 (1.2552)\tAccuracy 50.781 (45.258)\n",
      "Epoch: [0][1260/11585]\tLoss 1.1591 (1.2549)\tAccuracy 50.781 (45.269)\n",
      "Epoch: [0][1265/11585]\tLoss 1.1948 (1.2545)\tAccuracy 49.219 (45.289)\n",
      "Epoch: [0][1270/11585]\tLoss 1.2527 (1.2543)\tAccuracy 46.875 (45.300)\n",
      "Epoch: [0][1275/11585]\tLoss 1.1481 (1.2540)\tAccuracy 50.391 (45.320)\n",
      "Epoch: [0][1280/11585]\tLoss 1.1295 (1.2537)\tAccuracy 51.562 (45.334)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VYASRA~1\\AppData\\Local\\Temp/ipykernel_35844/3081133315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# train for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'current lr {:.5e}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# evaluate on validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VYASRA~1\\AppData\\Local\\Temp/ipykernel_35844/53511784.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch, device, print_freq)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Backward pass and update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # train for one epoch\n",
    "    print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "    train(train_dl, model, criterion, optimizer, epoch, device)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    eval(dev_in_dl, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FTTransformer",
   "language": "python",
   "name": "fttransformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
