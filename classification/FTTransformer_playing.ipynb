{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtdl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.543321e+09</td>\n",
       "      <td>26.968800</td>\n",
       "      <td>-99.248901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-17.526443</td>\n",
       "      <td>14.613571</td>\n",
       "      <td>754.263405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.600006</td>\n",
       "      <td>-2.750006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.538776e+09</td>\n",
       "      <td>29.374201</td>\n",
       "      <td>-100.927002</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>297.0</td>\n",
       "      <td>41.531032</td>\n",
       "      <td>26.992143</td>\n",
       "      <td>733.117168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.600006</td>\n",
       "      <td>17.950006</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552115e+09</td>\n",
       "      <td>22.149599</td>\n",
       "      <td>113.592003</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43.916531</td>\n",
       "      <td>18.842143</td>\n",
       "      <td>761.571076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233978</td>\n",
       "      <td>21.450006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.549566e+09</td>\n",
       "      <td>34.678699</td>\n",
       "      <td>-86.684799</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.240955</td>\n",
       "      <td>8.303571</td>\n",
       "      <td>747.524910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>16.150018</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.552910e+09</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>41.966667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.394660</td>\n",
       "      <td>6.451429</td>\n",
       "      <td>753.168113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>3.150018</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1.543321e+09      26.968800      -99.248901               2.0   \n",
       "1  1.538776e+09      29.374201     -100.927002              31.0   \n",
       "2  1.552115e+09      22.149599      113.592003              17.0   \n",
       "3  1.549566e+09      34.678699      -86.684799              24.0   \n",
       "4  1.552910e+09      46.066667       41.966667               9.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0              0.0             dry                  127.0     -17.526443   \n",
       "1             20.0  mild temperate                  297.0      41.531032   \n",
       "2             10.0  mild temperate                   -1.0      43.916531   \n",
       "3             20.0  mild temperate                  193.0      40.240955   \n",
       "4             20.0             dry                   90.0      30.394660   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            14.613571        754.263405  ...                0.0   \n",
       "1            26.992143        733.117168  ...                0.0   \n",
       "2            18.842143        761.571076  ...                0.0   \n",
       "3             8.303571        747.524910  ...                0.0   \n",
       "4             6.451429        753.168113  ...                0.0   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0             -2.600006             -2.750006   \n",
       "1                0.0             -0.600006             17.950006   \n",
       "2                0.0             -0.233978             21.450006   \n",
       "3                0.0              0.059448             16.150018   \n",
       "4                0.0              0.400024              3.150018   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              0.0                              0.0  \n",
       "1                            -12.0                             11.0  \n",
       "2                              1.0                              8.0  \n",
       "3                            -58.0                             41.0  \n",
       "4                             18.0                             92.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "train_path = '../../zipped/train.csv'\n",
    "dev_in_path = '../../zipped/dev_in.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539162000</td>\n",
       "      <td>-40.350000</td>\n",
       "      <td>-9.880000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>tropical</td>\n",
       "      <td>-843.0</td>\n",
       "      <td>31.782490</td>\n",
       "      <td>10.070714</td>\n",
       "      <td>765.631228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505035</td>\n",
       "      <td>2.647577</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1545006600</td>\n",
       "      <td>53.421299</td>\n",
       "      <td>-6.270070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-59.691521</td>\n",
       "      <td>7.005000</td>\n",
       "      <td>752.897615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400024</td>\n",
       "      <td>1.249994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540094400</td>\n",
       "      <td>-19.757700</td>\n",
       "      <td>63.361000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>dry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.250889</td>\n",
       "      <td>23.327143</td>\n",
       "      <td>763.115016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>21.050012</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1552611600</td>\n",
       "      <td>35.245899</td>\n",
       "      <td>47.009201</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>-23.755615</td>\n",
       "      <td>3.109286</td>\n",
       "      <td>609.419333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69672</td>\n",
       "      <td>5.1653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.349982</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1545631200</td>\n",
       "      <td>26.633333</td>\n",
       "      <td>118.150000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>210.0</td>\n",
       "      <td>33.040438</td>\n",
       "      <td>12.172143</td>\n",
       "      <td>734.678037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102081</td>\n",
       "      <td>11.513879</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1539162000     -40.350000       -9.880000              11.0   \n",
       "1  1545006600      53.421299       -6.270070               4.0   \n",
       "2  1540094400     -19.757700       63.361000              26.0   \n",
       "3  1552611600      35.245899       47.009201               5.0   \n",
       "4  1545631200      26.633333      118.150000              14.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0               10        tropical                 -843.0      31.782490   \n",
       "1               10  mild temperate                   67.0     -59.691521   \n",
       "2               10             dry                    6.0      35.250889   \n",
       "3               10  mild temperate                 1390.0     -23.755615   \n",
       "4               20  mild temperate                  210.0      33.040438   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            10.070714        765.631228  ...            0.00000   \n",
       "1             7.005000        752.897615  ...            0.00000   \n",
       "2            23.327143        763.115016  ...            0.00000   \n",
       "3             3.109286        609.419333  ...            1.69672   \n",
       "4            12.172143        734.678037  ...            0.00000   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0             0.0000                0.0           0.000000                0.0   \n",
       "1             0.0000                0.0           0.000000                0.0   \n",
       "2             0.0000                0.0           0.000000                0.0   \n",
       "3             5.1653                0.0           0.000049                0.0   \n",
       "4             0.0000                0.0           0.000000                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0              0.505035              2.647577   \n",
       "1                0.0             -0.400024              1.249994   \n",
       "2                0.0              0.100006             21.050012   \n",
       "3                0.0             -1.500000             -0.349982   \n",
       "4                0.0              0.102081             11.513879   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              2.0                              2.0  \n",
       "1                              0.0                              0.0  \n",
       "2                             -1.0                              1.0  \n",
       "3                            -12.0                             81.0  \n",
       "4                            -15.0                             83.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_in = pd.read_csv(dev_in_path)\n",
    "df_dev_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact_cwsm_class', 'climate', 'cmc_available', 'gfs_available', 'gfs_soil_temperature_available', 'gfs_timedelta_s', 'wrf_available']\n"
     ]
    }
   ],
   "source": [
    "# Identify the categorical features\n",
    "cat_features = []\n",
    "for col in df_dev_in:\n",
    "    values = df_dev_in[col].tolist()\n",
    "    unique = list(dict.fromkeys(values))\n",
    "    if len(unique) < 20:\n",
    "        cat_features.append(col)\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1545219635.2602534, 27.3491997995972, -19.454721235367906, 15.030736293991083, 0.0, 'mild temperate', 309.93658796685, -2.7249874731371273, 15.053651434869764, 731.2756530851661, 289.1659257771938, 0.0513848381221949, 287.04881832634976, 287.0853175734476, 287.0339327353252, 258.9922501121575, 274.97475431188, 282.77351197349384, 285.8909051108904, 281.3276019215079, 7.660611531165116, 5.534873822269684, 14.704511863943937, 12.971739936778564, 8.78866233485156, 7.2775056043593676, 0.009529923266778687, 0.00859610917297107, 6.413124162323838, 0.2673820249969054, 0.027512247376225554, 0.008222988603064724, 3.866966535018241e-05, -0.0020003342605871715, -0.05948973513452053, 10.42531664950694, 5.2929354486362215, 1.8376276146288066, 0.4768480677913728, -0.09701087752828826, -0.14489588205685547, 0.22814633531193007, 0.2219977889627698, 0.30237136633108197, 0.18710502254215602, 97345.58898593165, 97344.2322319218, 101661.80541725569, 137.95607755299883, 5728.521789532874, 3094.1520088604207, 1504.0103447668691, 797.3523991534046, 37.07459687934277, 1.0, 49.846809128188646, 0.1397615836326275, 3193.5639279354186, 7.875858105871922, 6.318132459416767e-05, 1.0, 0.7377752698462914, 1.4802979068821847e-07, 44.060568770740154, 65.5584417745946, 21.504211618918216, 0.12521102946095294, 731.2233402176113, 0.008033159667266226, -1819.1629409387926, 1.0, -67.28908852176293, -61.45628742576919, -55.78256429751954, -48.40214544214997, -40.239168086804234, -32.42869414585041, -25.500304955545896, -19.46492327470662, -64.14897479374763, -14.198140237399796, -9.559197665244577, -5.41065208747797, -1.7061806962327069, -67.16019146882202, 1.6164132948853693, 4.626240268496011, 7.342803033488016, 9.823743835990618, 12.211598927309758, 13.416417220454605, 14.645629188839976, 15.883642604926143, 15.470014013486876, 0.04935516746916531, 15.483820810290512, 15.519105578698078, 0.0, 38.702409655095366, 18.238931974809194, 16.836185354724595, -0.01449744864394827, -0.04546247978039495, 3.7423347274135303, 1.0, 287.9381975660448, 287.95573134943953, 97994.65417635812, 0.7362492437923865, -0.05505970029976019, -0.08985226965162621, 0.12765691011045083, 0.004114918452075356, 0.0011533477698721, 0.0, 287.9381975660448, 0.017533783394746115, 0.40059827557247835, 6.813722437896308, 0.016303617495967773, 0.28368564249287337, 0.0017981805217585445, 0.029310427897984142, 0.0005846442774275127, 0.008807632880492246, 0.013054502087814274, 7.888782940886862, 0.0073836321184068306, 18.246277597971417])\n"
     ]
    }
   ],
   "source": [
    "# !pip install scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "nan_replacements = {}\n",
    "for col in df_train:\n",
    "    if col in cat_features:\n",
    "        nan_replacements[col] = stats.mode(np.asarray(df_train[col].tolist()))[0][0]\n",
    "        # print(nan_replacements[col])\n",
    "    else:\n",
    "        nan_replacements[col] = np.mean(np.asarray(df_train[col].dropna().tolist()))\n",
    "print(nan_replacements.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nans in train and dev\n",
    "for col in df_train:\n",
    "    df_train[col] = df_train[col].fillna(nan_replacements[col])\n",
    "    df_dev_in[col] = df_dev_in[col].fillna(nan_replacements[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    X: Dict[str, np.ndarray], normalization: str, seed: int, noise: float = 1e-3\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    # X ~ {'train': <train_size x n_features>, 'val': <val_size x n_features>, 'test': <test_size x n_features>}\n",
    "    X_train = X['train']\n",
    "    if normalization == 'standard':\n",
    "        normalizer = sklearn.preprocessing.StandardScaler()\n",
    "    elif normalization == 'quantile':\n",
    "        normalizer = sklearn.preprocessing.QuantileTransformer(\n",
    "            output_distribution='normal',\n",
    "            n_quantiles=max(min(X['train'].shape[0] // 30, 1000), 10),\n",
    "            subsample=1e9,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        if noise:\n",
    "            X_train = X_train.copy()\n",
    "            stds = np.std(X_train, axis=0, keepdims=True)\n",
    "            noise_std = noise / np.maximum(stds, noise)\n",
    "            X_train += noise_std * np.random.default_rng(seed).standard_normal(\n",
    "                X_train.shape\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f'unknown normalization: {normalization}')\n",
    "    normalizer.fit(X_train)\n",
    "    return {k: normalizer.transform(v) for k, v in X.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise using train data stats\n",
    "# Quantile normalisation is used (maps to a normal distribution)\n",
    "X_train_np = np.asarray(df_train.iloc[:,6:])\n",
    "X_dev_in_np = np.asarray(df_dev_in.iloc[:,6:])\n",
    "X = {'train': X_train_np, 'dev_in': X_dev_in_np}\n",
    "X = normalize(X, normalization='quantile', seed=seed)\n",
    "X_train_np = X['train']\n",
    "X_dev_in_np = X['dev_in']\n",
    "\n",
    "X_train = torch.FloatTensor(X_train_np)\n",
    "X_dev_in = torch.FloatTensor(X_dev_in_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess into tensors\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_lab_to_ind(data_df):\n",
    "    '''\n",
    "    Prepare a label to index map\n",
    "    '''\n",
    "    y_fact = set(list(data_df['fact_cwsm_class']))\n",
    "    lab_to_ind = {}\n",
    "    for i, lab in enumerate(y_fact):\n",
    "        lab_to_ind[lab] = i\n",
    "    return lab_to_ind\n",
    "\n",
    "lab_to_ind = get_lab_to_ind(df_train)\n",
    "batch_size = 1024\n",
    "\n",
    "# Train\n",
    "y_train = np.asarray(df_train['fact_cwsm_class'])\n",
    "y_train = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_train]))\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Dev in\n",
    "y_dev_in = df_dev_in['fact_cwsm_class']\n",
    "y_dev_in = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_dev_in]))\n",
    "\n",
    "dev_in_ds = TensorDataset(X_dev_in, y_dev_in)\n",
    "dev_in_dl = DataLoader(dev_in_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got CUDA!\n"
     ]
    }
   ],
   "source": [
    "# Get the device\n",
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Got CUDA!\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"No CUDA found\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTTransformer(\n",
       "  (feature_tokenizer): FeatureTokenizer(\n",
       "    (num_tokenizer): NumericalFeatureTokenizer()\n",
       "  )\n",
       "  (cls_token): CLSToken()\n",
       "  (transformer): Transformer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (head): Head(\n",
       "      (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): ReLU()\n",
       "      (linear): Linear(in_features=192, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Feature Transformer Model\n",
    "\n",
    "model = rtdl.FTTransformer.make_default(\n",
    "    n_num_features=X_train.shape[1],\n",
    "    cat_cardinalities=None,\n",
    "    last_layer_query_idx=[-1],\n",
    "    d_out=len(lab_to_ind)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "\n",
    "# These params don't need to be set as we will use a default optimizer\n",
    "# lr = 0.01\n",
    "# weight_decay = 0.9\n",
    "\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters(), lr=lr,\n",
    "                          weight_decay=weight_decay)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function criterion\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline to apply model\n",
    "def apply_model(model, x_num, x_cat=None):\n",
    "    '''\n",
    "    FTTransformer expects numerical and categorical inputs separately\n",
    "    '''\n",
    "    return model(x_num, x_cat) if isinstance(model, rtdl.FTTransformer) else model(x_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Function\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy_topk(output, target, k=1):\n",
    "    \"\"\"Computes the topk accuracy\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = torch.topk(output, k=k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "    res_total = 0\n",
    "    for curr_k in range(k):\n",
    "      curr_ind = pred[:,curr_k]\n",
    "      num_eq = torch.eq(curr_ind, target).sum()\n",
    "      acc = num_eq/len(output)\n",
    "      res_total += acc\n",
    "    return res_total*100\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, device, print_freq=100):\n",
    "    '''\n",
    "    Run one train epoch\n",
    "    '''\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (x, target) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = apply_model(model, x)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # Backward pass and update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy_topk(logits.data, target)\n",
    "        accs.update(acc.item(), x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                    'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                    'Accuracy {prec.val:.3f} ({prec.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader),\n",
    "                      loss=losses, prec=accs))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(val_loader, model, criterion, device):\n",
    "    '''\n",
    "    Run evaluation\n",
    "    '''\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for i, (x, target) in enumerate(val_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = apply_model(model, x)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy_topk(logits.data, target)\n",
    "        accs.update(acc.item(), x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "    print('Dev in\\t Loss ({loss.avg:.4f})\\t'\n",
    "            'Accuracy ({prec.avg:.3f})\\n'.format(\n",
    "              loss=losses, prec=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-04\n",
      "Epoch: [0][0/3057]\tLoss 2.2171 (2.2171)\tAccuracy 4.590 (4.590)\n",
      "Epoch: [0][100/3057]\tLoss 1.0726 (1.2146)\tAccuracy 56.055 (50.868)\n",
      "Epoch: [0][200/3057]\tLoss 1.0516 (1.1320)\tAccuracy 56.152 (54.065)\n",
      "Epoch: [0][300/3057]\tLoss 1.0374 (1.0955)\tAccuracy 56.348 (55.329)\n",
      "Epoch: [0][400/3057]\tLoss 1.0069 (1.0721)\tAccuracy 58.984 (56.128)\n",
      "Epoch: [0][500/3057]\tLoss 0.9193 (1.0581)\tAccuracy 62.402 (56.545)\n",
      "Epoch: [0][600/3057]\tLoss 0.9602 (1.0468)\tAccuracy 59.961 (56.899)\n",
      "Epoch: [0][700/3057]\tLoss 0.9750 (1.0379)\tAccuracy 59.668 (57.212)\n",
      "Epoch: [0][800/3057]\tLoss 0.9383 (1.0318)\tAccuracy 61.523 (57.415)\n",
      "Epoch: [0][900/3057]\tLoss 0.9990 (1.0262)\tAccuracy 59.277 (57.579)\n",
      "Epoch: [0][1000/3057]\tLoss 0.9861 (1.0214)\tAccuracy 57.812 (57.752)\n",
      "Epoch: [0][1100/3057]\tLoss 0.9398 (1.0172)\tAccuracy 60.840 (57.905)\n",
      "Epoch: [0][1200/3057]\tLoss 0.9479 (1.0136)\tAccuracy 60.742 (58.044)\n",
      "Epoch: [0][1300/3057]\tLoss 0.9662 (1.0104)\tAccuracy 59.277 (58.166)\n",
      "Epoch: [0][1400/3057]\tLoss 0.9452 (1.0074)\tAccuracy 60.449 (58.277)\n",
      "Epoch: [0][1500/3057]\tLoss 0.9566 (1.0047)\tAccuracy 58.887 (58.381)\n",
      "Epoch: [0][1600/3057]\tLoss 0.9819 (1.0024)\tAccuracy 60.254 (58.468)\n",
      "Epoch: [0][1700/3057]\tLoss 0.9736 (1.0000)\tAccuracy 58.789 (58.561)\n",
      "Epoch: [0][1800/3057]\tLoss 1.0037 (0.9980)\tAccuracy 56.348 (58.629)\n",
      "Epoch: [0][1900/3057]\tLoss 1.0204 (0.9961)\tAccuracy 56.445 (58.692)\n",
      "Epoch: [0][2000/3057]\tLoss 0.9621 (0.9942)\tAccuracy 59.277 (58.760)\n",
      "Epoch: [0][2100/3057]\tLoss 0.9812 (0.9925)\tAccuracy 56.934 (58.830)\n",
      "Epoch: [0][2200/3057]\tLoss 0.9265 (0.9908)\tAccuracy 62.598 (58.887)\n",
      "Epoch: [0][2300/3057]\tLoss 0.9597 (0.9894)\tAccuracy 59.668 (58.939)\n",
      "Epoch: [0][2400/3057]\tLoss 0.9872 (0.9878)\tAccuracy 58.398 (58.999)\n",
      "Epoch: [0][2500/3057]\tLoss 0.9667 (0.9866)\tAccuracy 59.375 (59.040)\n",
      "Epoch: [0][2600/3057]\tLoss 0.9945 (0.9854)\tAccuracy 58.691 (59.085)\n",
      "Epoch: [0][2700/3057]\tLoss 0.9742 (0.9842)\tAccuracy 59.375 (59.129)\n",
      "Epoch: [0][2800/3057]\tLoss 1.0117 (0.9831)\tAccuracy 58.984 (59.172)\n",
      "Epoch: [0][2900/3057]\tLoss 0.9982 (0.9819)\tAccuracy 58.594 (59.215)\n",
      "Epoch: [0][3000/3057]\tLoss 0.9567 (0.9807)\tAccuracy 59.766 (59.268)\n",
      "Dev in\t Loss (0.9395)\tAccuracy (60.792)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [1][0/3057]\tLoss 0.9109 (0.9109)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [1][100/3057]\tLoss 0.8780 (0.9551)\tAccuracy 62.891 (60.359)\n",
      "Epoch: [1][200/3057]\tLoss 0.9338 (0.9502)\tAccuracy 63.184 (60.427)\n",
      "Epoch: [1][300/3057]\tLoss 0.9411 (0.9492)\tAccuracy 59.668 (60.441)\n",
      "Epoch: [1][400/3057]\tLoss 0.9491 (0.9489)\tAccuracy 62.109 (60.471)\n",
      "Epoch: [1][500/3057]\tLoss 0.9730 (0.9483)\tAccuracy 59.473 (60.474)\n",
      "Epoch: [1][600/3057]\tLoss 0.9488 (0.9478)\tAccuracy 61.523 (60.511)\n",
      "Epoch: [1][700/3057]\tLoss 0.9693 (0.9479)\tAccuracy 58.789 (60.487)\n",
      "Epoch: [1][800/3057]\tLoss 0.9493 (0.9475)\tAccuracy 60.938 (60.518)\n",
      "Epoch: [1][900/3057]\tLoss 0.9650 (0.9471)\tAccuracy 58.496 (60.562)\n",
      "Epoch: [1][1000/3057]\tLoss 0.9741 (0.9469)\tAccuracy 58.203 (60.578)\n",
      "Epoch: [1][1100/3057]\tLoss 0.9033 (0.9462)\tAccuracy 63.086 (60.612)\n",
      "Epoch: [1][1200/3057]\tLoss 0.9726 (0.9458)\tAccuracy 58.984 (60.622)\n",
      "Epoch: [1][1300/3057]\tLoss 0.9783 (0.9453)\tAccuracy 58.691 (60.662)\n",
      "Epoch: [1][1400/3057]\tLoss 0.9456 (0.9450)\tAccuracy 59.961 (60.672)\n",
      "Epoch: [1][1500/3057]\tLoss 0.9027 (0.9444)\tAccuracy 61.621 (60.691)\n",
      "Epoch: [1][1600/3057]\tLoss 0.9632 (0.9442)\tAccuracy 60.547 (60.715)\n",
      "Epoch: [1][1700/3057]\tLoss 0.9948 (0.9437)\tAccuracy 59.668 (60.732)\n",
      "Epoch: [1][1800/3057]\tLoss 0.9526 (0.9433)\tAccuracy 62.500 (60.742)\n",
      "Epoch: [1][1900/3057]\tLoss 0.9659 (0.9430)\tAccuracy 60.254 (60.764)\n",
      "Epoch: [1][2000/3057]\tLoss 0.8931 (0.9427)\tAccuracy 62.988 (60.786)\n",
      "Epoch: [1][2100/3057]\tLoss 0.9461 (0.9425)\tAccuracy 61.914 (60.793)\n",
      "Epoch: [1][2200/3057]\tLoss 0.9160 (0.9423)\tAccuracy 62.012 (60.803)\n",
      "Epoch: [1][2300/3057]\tLoss 0.9155 (0.9420)\tAccuracy 61.621 (60.822)\n",
      "Epoch: [1][2400/3057]\tLoss 0.9521 (0.9415)\tAccuracy 61.035 (60.847)\n",
      "Epoch: [1][2500/3057]\tLoss 0.9447 (0.9412)\tAccuracy 61.133 (60.863)\n",
      "Epoch: [1][2600/3057]\tLoss 0.9313 (0.9409)\tAccuracy 63.965 (60.872)\n",
      "Epoch: [1][2700/3057]\tLoss 0.8969 (0.9407)\tAccuracy 61.426 (60.884)\n",
      "Epoch: [1][2800/3057]\tLoss 0.9534 (0.9405)\tAccuracy 59.668 (60.897)\n",
      "Epoch: [1][2900/3057]\tLoss 0.9700 (0.9401)\tAccuracy 59.180 (60.911)\n",
      "Epoch: [1][3000/3057]\tLoss 0.9570 (0.9397)\tAccuracy 59.668 (60.927)\n",
      "Dev in\t Loss (0.9189)\tAccuracy (61.884)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [2][0/3057]\tLoss 0.9314 (0.9314)\tAccuracy 62.207 (62.207)\n",
      "Epoch: [2][100/3057]\tLoss 0.9176 (0.9310)\tAccuracy 61.230 (61.240)\n",
      "Epoch: [2][200/3057]\tLoss 0.9186 (0.9303)\tAccuracy 62.207 (61.362)\n",
      "Epoch: [2][300/3057]\tLoss 0.9416 (0.9311)\tAccuracy 60.547 (61.244)\n",
      "Epoch: [2][400/3057]\tLoss 0.9121 (0.9310)\tAccuracy 62.305 (61.268)\n",
      "Epoch: [2][500/3057]\tLoss 0.9379 (0.9300)\tAccuracy 59.668 (61.352)\n",
      "Epoch: [2][600/3057]\tLoss 0.9188 (0.9294)\tAccuracy 62.012 (61.387)\n",
      "Epoch: [2][700/3057]\tLoss 0.9065 (0.9292)\tAccuracy 61.621 (61.404)\n",
      "Epoch: [2][800/3057]\tLoss 0.9486 (0.9290)\tAccuracy 59.180 (61.417)\n",
      "Epoch: [2][900/3057]\tLoss 0.9148 (0.9287)\tAccuracy 62.012 (61.433)\n",
      "Epoch: [2][1000/3057]\tLoss 0.8899 (0.9280)\tAccuracy 62.500 (61.467)\n",
      "Epoch: [2][1100/3057]\tLoss 0.9169 (0.9282)\tAccuracy 61.816 (61.447)\n",
      "Epoch: [2][1200/3057]\tLoss 0.9254 (0.9280)\tAccuracy 60.352 (61.453)\n",
      "Epoch: [2][1300/3057]\tLoss 0.8953 (0.9278)\tAccuracy 63.184 (61.463)\n",
      "Epoch: [2][1400/3057]\tLoss 0.9248 (0.9278)\tAccuracy 61.914 (61.444)\n",
      "Epoch: [2][1500/3057]\tLoss 0.9162 (0.9277)\tAccuracy 60.742 (61.466)\n",
      "Epoch: [2][1600/3057]\tLoss 0.9249 (0.9276)\tAccuracy 60.352 (61.470)\n",
      "Epoch: [2][1700/3057]\tLoss 0.9517 (0.9276)\tAccuracy 58.984 (61.477)\n",
      "Epoch: [2][1800/3057]\tLoss 0.9298 (0.9274)\tAccuracy 61.035 (61.474)\n",
      "Epoch: [2][1900/3057]\tLoss 0.9063 (0.9274)\tAccuracy 64.355 (61.473)\n",
      "Epoch: [2][2000/3057]\tLoss 0.9270 (0.9272)\tAccuracy 61.035 (61.480)\n",
      "Epoch: [2][2100/3057]\tLoss 0.8955 (0.9271)\tAccuracy 61.426 (61.480)\n",
      "Epoch: [2][2200/3057]\tLoss 0.9158 (0.9268)\tAccuracy 60.156 (61.493)\n",
      "Epoch: [2][2300/3057]\tLoss 0.9291 (0.9267)\tAccuracy 62.012 (61.493)\n",
      "Epoch: [2][2400/3057]\tLoss 0.9673 (0.9263)\tAccuracy 61.133 (61.512)\n",
      "Epoch: [2][2500/3057]\tLoss 0.9048 (0.9259)\tAccuracy 64.160 (61.531)\n",
      "Epoch: [2][2600/3057]\tLoss 0.9163 (0.9257)\tAccuracy 59.766 (61.538)\n",
      "Epoch: [2][2700/3057]\tLoss 0.9350 (0.9257)\tAccuracy 60.547 (61.535)\n",
      "Epoch: [2][2800/3057]\tLoss 0.9252 (0.9256)\tAccuracy 62.402 (61.548)\n",
      "Epoch: [2][2900/3057]\tLoss 0.9128 (0.9254)\tAccuracy 61.523 (61.559)\n",
      "Epoch: [2][3000/3057]\tLoss 0.9088 (0.9252)\tAccuracy 61.426 (61.564)\n",
      "Dev in\t Loss (0.9077)\tAccuracy (62.350)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [3][0/3057]\tLoss 0.8990 (0.8990)\tAccuracy 60.547 (60.547)\n",
      "Epoch: [3][100/3057]\tLoss 0.9152 (0.9230)\tAccuracy 60.938 (61.735)\n",
      "Epoch: [3][200/3057]\tLoss 0.8886 (0.9213)\tAccuracy 63.184 (61.764)\n",
      "Epoch: [3][300/3057]\tLoss 0.9411 (0.9197)\tAccuracy 60.938 (61.857)\n",
      "Epoch: [3][400/3057]\tLoss 0.9714 (0.9195)\tAccuracy 60.352 (61.875)\n",
      "Epoch: [3][500/3057]\tLoss 0.9200 (0.9194)\tAccuracy 62.402 (61.865)\n",
      "Epoch: [3][600/3057]\tLoss 0.9136 (0.9188)\tAccuracy 63.184 (61.917)\n",
      "Epoch: [3][700/3057]\tLoss 0.9118 (0.9185)\tAccuracy 62.988 (61.939)\n",
      "Epoch: [3][800/3057]\tLoss 0.9068 (0.9180)\tAccuracy 62.598 (61.953)\n",
      "Epoch: [3][900/3057]\tLoss 0.9243 (0.9179)\tAccuracy 61.914 (61.949)\n",
      "Epoch: [3][1000/3057]\tLoss 0.8789 (0.9176)\tAccuracy 63.086 (61.942)\n",
      "Epoch: [3][1100/3057]\tLoss 0.9434 (0.9176)\tAccuracy 59.570 (61.944)\n",
      "Epoch: [3][1200/3057]\tLoss 0.8874 (0.9175)\tAccuracy 62.988 (61.947)\n",
      "Epoch: [3][1300/3057]\tLoss 0.9039 (0.9173)\tAccuracy 63.281 (61.959)\n",
      "Epoch: [3][1400/3057]\tLoss 0.9121 (0.9170)\tAccuracy 60.840 (61.954)\n",
      "Epoch: [3][1500/3057]\tLoss 0.9454 (0.9168)\tAccuracy 62.695 (61.956)\n",
      "Epoch: [3][1600/3057]\tLoss 0.9047 (0.9168)\tAccuracy 61.719 (61.973)\n",
      "Epoch: [3][1700/3057]\tLoss 0.9358 (0.9165)\tAccuracy 57.422 (61.991)\n",
      "Epoch: [3][1800/3057]\tLoss 0.8678 (0.9164)\tAccuracy 63.574 (61.986)\n",
      "Epoch: [3][1900/3057]\tLoss 0.9012 (0.9164)\tAccuracy 63.086 (61.982)\n",
      "Epoch: [3][2000/3057]\tLoss 0.8929 (0.9162)\tAccuracy 62.402 (61.996)\n",
      "Epoch: [3][2100/3057]\tLoss 0.9168 (0.9161)\tAccuracy 62.109 (61.993)\n",
      "Epoch: [3][2200/3057]\tLoss 0.9102 (0.9160)\tAccuracy 62.891 (62.002)\n",
      "Epoch: [3][2300/3057]\tLoss 0.8742 (0.9160)\tAccuracy 63.965 (62.000)\n",
      "Epoch: [3][2400/3057]\tLoss 0.9122 (0.9158)\tAccuracy 60.938 (62.009)\n",
      "Epoch: [3][2500/3057]\tLoss 0.9190 (0.9157)\tAccuracy 62.500 (62.012)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2600/3057]\tLoss 0.9067 (0.9154)\tAccuracy 62.891 (62.023)\n",
      "Epoch: [3][2700/3057]\tLoss 0.9372 (0.9154)\tAccuracy 61.914 (62.027)\n",
      "Epoch: [3][2800/3057]\tLoss 0.9391 (0.9153)\tAccuracy 59.766 (62.036)\n",
      "Epoch: [3][2900/3057]\tLoss 0.9274 (0.9151)\tAccuracy 63.281 (62.045)\n",
      "Epoch: [3][3000/3057]\tLoss 0.9087 (0.9151)\tAccuracy 62.402 (62.051)\n",
      "Dev in\t Loss (0.8960)\tAccuracy (62.854)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [4][0/3057]\tLoss 0.9282 (0.9282)\tAccuracy 62.305 (62.305)\n",
      "Epoch: [4][100/3057]\tLoss 0.8957 (0.9130)\tAccuracy 63.672 (62.301)\n",
      "Epoch: [4][200/3057]\tLoss 0.8792 (0.9098)\tAccuracy 63.770 (62.402)\n",
      "Epoch: [4][300/3057]\tLoss 0.9082 (0.9091)\tAccuracy 61.523 (62.376)\n",
      "Epoch: [4][400/3057]\tLoss 0.9404 (0.9081)\tAccuracy 62.012 (62.398)\n",
      "Epoch: [4][500/3057]\tLoss 0.9263 (0.9075)\tAccuracy 61.426 (62.383)\n",
      "Epoch: [4][600/3057]\tLoss 0.8960 (0.9079)\tAccuracy 63.574 (62.354)\n",
      "Epoch: [4][700/3057]\tLoss 0.8933 (0.9080)\tAccuracy 64.453 (62.352)\n",
      "Epoch: [4][800/3057]\tLoss 0.8865 (0.9081)\tAccuracy 63.477 (62.367)\n",
      "Epoch: [4][900/3057]\tLoss 0.8852 (0.9081)\tAccuracy 63.477 (62.369)\n",
      "Epoch: [4][1000/3057]\tLoss 0.9227 (0.9082)\tAccuracy 61.035 (62.361)\n",
      "Epoch: [4][1100/3057]\tLoss 0.9162 (0.9085)\tAccuracy 62.500 (62.360)\n",
      "Epoch: [4][1200/3057]\tLoss 0.9141 (0.9086)\tAccuracy 59.863 (62.355)\n",
      "Epoch: [4][1300/3057]\tLoss 0.9776 (0.9084)\tAccuracy 59.375 (62.369)\n",
      "Epoch: [4][1400/3057]\tLoss 0.9214 (0.9078)\tAccuracy 61.035 (62.392)\n",
      "Epoch: [4][1500/3057]\tLoss 0.8759 (0.9075)\tAccuracy 64.551 (62.401)\n",
      "Epoch: [4][1600/3057]\tLoss 0.9160 (0.9079)\tAccuracy 63.086 (62.378)\n",
      "Epoch: [4][1700/3057]\tLoss 0.9299 (0.9078)\tAccuracy 61.816 (62.378)\n",
      "Epoch: [4][1800/3057]\tLoss 0.8880 (0.9076)\tAccuracy 61.816 (62.386)\n",
      "Epoch: [4][1900/3057]\tLoss 0.8635 (0.9076)\tAccuracy 64.746 (62.384)\n",
      "Epoch: [4][2000/3057]\tLoss 0.9201 (0.9073)\tAccuracy 61.816 (62.395)\n",
      "Epoch: [4][2100/3057]\tLoss 0.9018 (0.9071)\tAccuracy 62.695 (62.414)\n",
      "Epoch: [4][2200/3057]\tLoss 0.8880 (0.9070)\tAccuracy 62.109 (62.416)\n",
      "Epoch: [4][2300/3057]\tLoss 0.8781 (0.9070)\tAccuracy 62.012 (62.408)\n",
      "Epoch: [4][2400/3057]\tLoss 0.9257 (0.9068)\tAccuracy 60.352 (62.419)\n",
      "Epoch: [4][2500/3057]\tLoss 0.9075 (0.9068)\tAccuracy 61.133 (62.415)\n",
      "Epoch: [4][2600/3057]\tLoss 0.9178 (0.9066)\tAccuracy 60.547 (62.412)\n",
      "Epoch: [4][2700/3057]\tLoss 0.8586 (0.9065)\tAccuracy 64.551 (62.419)\n",
      "Epoch: [4][2800/3057]\tLoss 0.8930 (0.9065)\tAccuracy 65.039 (62.423)\n",
      "Epoch: [4][2900/3057]\tLoss 0.8937 (0.9064)\tAccuracy 62.793 (62.426)\n",
      "Epoch: [4][3000/3057]\tLoss 0.8959 (0.9064)\tAccuracy 64.160 (62.428)\n",
      "Dev in\t Loss (0.8882)\tAccuracy (63.340)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [5][0/3057]\tLoss 0.8744 (0.8744)\tAccuracy 64.453 (64.453)\n",
      "Epoch: [5][100/3057]\tLoss 0.9100 (0.9004)\tAccuracy 63.281 (62.820)\n",
      "Epoch: [5][200/3057]\tLoss 0.9231 (0.9019)\tAccuracy 61.230 (62.676)\n",
      "Epoch: [5][300/3057]\tLoss 0.8519 (0.9001)\tAccuracy 64.355 (62.800)\n",
      "Epoch: [5][400/3057]\tLoss 0.9050 (0.9008)\tAccuracy 61.719 (62.786)\n",
      "Epoch: [5][500/3057]\tLoss 0.9268 (0.9015)\tAccuracy 61.035 (62.695)\n",
      "Epoch: [5][600/3057]\tLoss 0.9421 (0.9014)\tAccuracy 60.254 (62.706)\n",
      "Epoch: [5][700/3057]\tLoss 0.9115 (0.9013)\tAccuracy 62.793 (62.722)\n",
      "Epoch: [5][800/3057]\tLoss 0.9047 (0.9009)\tAccuracy 62.305 (62.749)\n",
      "Epoch: [5][900/3057]\tLoss 0.9237 (0.9007)\tAccuracy 62.012 (62.752)\n",
      "Epoch: [5][1000/3057]\tLoss 0.9205 (0.9008)\tAccuracy 62.793 (62.742)\n",
      "Epoch: [5][1100/3057]\tLoss 0.8792 (0.9004)\tAccuracy 62.402 (62.754)\n",
      "Epoch: [5][1200/3057]\tLoss 0.9259 (0.9001)\tAccuracy 62.891 (62.764)\n",
      "Epoch: [5][1300/3057]\tLoss 0.9274 (0.9003)\tAccuracy 60.547 (62.753)\n",
      "Epoch: [5][1400/3057]\tLoss 0.9144 (0.9004)\tAccuracy 62.500 (62.737)\n",
      "Epoch: [5][1500/3057]\tLoss 0.8939 (0.9003)\tAccuracy 63.672 (62.739)\n",
      "Epoch: [5][1600/3057]\tLoss 0.9142 (0.9001)\tAccuracy 63.574 (62.750)\n",
      "Epoch: [5][1700/3057]\tLoss 0.8646 (0.9000)\tAccuracy 63.965 (62.744)\n",
      "Epoch: [5][1800/3057]\tLoss 0.9079 (0.8998)\tAccuracy 62.598 (62.755)\n",
      "Epoch: [5][1900/3057]\tLoss 0.8865 (0.8998)\tAccuracy 62.305 (62.747)\n",
      "Epoch: [5][2000/3057]\tLoss 0.9063 (0.9000)\tAccuracy 62.598 (62.742)\n",
      "Epoch: [5][2100/3057]\tLoss 0.8420 (0.8998)\tAccuracy 66.016 (62.754)\n",
      "Epoch: [5][2200/3057]\tLoss 0.8894 (0.8997)\tAccuracy 64.258 (62.754)\n",
      "Epoch: [5][2300/3057]\tLoss 0.9075 (0.8996)\tAccuracy 63.965 (62.759)\n",
      "Epoch: [5][2400/3057]\tLoss 0.8770 (0.8996)\tAccuracy 62.305 (62.758)\n",
      "Epoch: [5][2500/3057]\tLoss 0.9100 (0.8996)\tAccuracy 61.914 (62.763)\n",
      "Epoch: [5][2600/3057]\tLoss 0.9047 (0.8995)\tAccuracy 63.086 (62.773)\n",
      "Epoch: [5][2700/3057]\tLoss 0.8745 (0.8995)\tAccuracy 64.746 (62.775)\n",
      "Epoch: [5][2800/3057]\tLoss 0.8661 (0.8993)\tAccuracy 63.574 (62.780)\n",
      "Epoch: [5][2900/3057]\tLoss 0.8924 (0.8993)\tAccuracy 62.988 (62.776)\n",
      "Epoch: [5][3000/3057]\tLoss 0.9430 (0.8991)\tAccuracy 60.156 (62.779)\n",
      "Dev in\t Loss (0.8856)\tAccuracy (63.374)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [6][0/3057]\tLoss 0.8715 (0.8715)\tAccuracy 63.574 (63.574)\n",
      "Epoch: [6][100/3057]\tLoss 0.8529 (0.8930)\tAccuracy 63.574 (63.002)\n",
      "Epoch: [6][200/3057]\tLoss 0.8916 (0.8951)\tAccuracy 63.281 (62.950)\n",
      "Epoch: [6][300/3057]\tLoss 0.8861 (0.8938)\tAccuracy 62.402 (63.009)\n",
      "Epoch: [6][400/3057]\tLoss 0.8649 (0.8950)\tAccuracy 66.113 (62.976)\n",
      "Epoch: [6][500/3057]\tLoss 0.8503 (0.8937)\tAccuracy 65.723 (63.017)\n",
      "Epoch: [6][600/3057]\tLoss 0.8668 (0.8932)\tAccuracy 64.941 (63.066)\n",
      "Epoch: [6][700/3057]\tLoss 0.8503 (0.8931)\tAccuracy 65.527 (63.098)\n",
      "Epoch: [6][800/3057]\tLoss 0.8737 (0.8921)\tAccuracy 63.770 (63.140)\n",
      "Epoch: [6][900/3057]\tLoss 0.8912 (0.8921)\tAccuracy 64.648 (63.130)\n",
      "Epoch: [6][1000/3057]\tLoss 0.8620 (0.8919)\tAccuracy 66.602 (63.142)\n",
      "Epoch: [6][1100/3057]\tLoss 0.9025 (0.8920)\tAccuracy 61.621 (63.135)\n",
      "Epoch: [6][1200/3057]\tLoss 0.8959 (0.8922)\tAccuracy 64.160 (63.123)\n",
      "Epoch: [6][1300/3057]\tLoss 0.9024 (0.8923)\tAccuracy 61.426 (63.118)\n",
      "Epoch: [6][1400/3057]\tLoss 0.8893 (0.8927)\tAccuracy 61.621 (63.082)\n",
      "Epoch: [6][1500/3057]\tLoss 0.8902 (0.8927)\tAccuracy 62.988 (63.080)\n",
      "Epoch: [6][1600/3057]\tLoss 0.8827 (0.8927)\tAccuracy 63.770 (63.077)\n",
      "Epoch: [6][1700/3057]\tLoss 0.8655 (0.8928)\tAccuracy 65.039 (63.070)\n",
      "Epoch: [6][1800/3057]\tLoss 0.8676 (0.8928)\tAccuracy 64.648 (63.067)\n",
      "Epoch: [6][1900/3057]\tLoss 0.9453 (0.8928)\tAccuracy 60.449 (63.062)\n",
      "Epoch: [6][2000/3057]\tLoss 0.8813 (0.8926)\tAccuracy 64.648 (63.071)\n",
      "Epoch: [6][2100/3057]\tLoss 0.8907 (0.8928)\tAccuracy 66.113 (63.066)\n",
      "Epoch: [6][2200/3057]\tLoss 0.8742 (0.8927)\tAccuracy 63.672 (63.065)\n",
      "Epoch: [6][2300/3057]\tLoss 0.8723 (0.8927)\tAccuracy 65.918 (63.067)\n",
      "Epoch: [6][2400/3057]\tLoss 0.8876 (0.8927)\tAccuracy 62.988 (63.062)\n",
      "Epoch: [6][2500/3057]\tLoss 0.9032 (0.8926)\tAccuracy 61.719 (63.067)\n",
      "Epoch: [6][2600/3057]\tLoss 0.8497 (0.8924)\tAccuracy 64.941 (63.075)\n",
      "Epoch: [6][2700/3057]\tLoss 0.8831 (0.8924)\tAccuracy 63.086 (63.080)\n",
      "Epoch: [6][2800/3057]\tLoss 0.8292 (0.8924)\tAccuracy 65.527 (63.074)\n",
      "Epoch: [6][2900/3057]\tLoss 0.8601 (0.8924)\tAccuracy 64.160 (63.076)\n",
      "Epoch: [6][3000/3057]\tLoss 0.9070 (0.8923)\tAccuracy 61.133 (63.080)\n",
      "Dev in\t Loss (0.8803)\tAccuracy (63.700)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [7][0/3057]\tLoss 0.8744 (0.8744)\tAccuracy 64.062 (64.062)\n",
      "Epoch: [7][100/3057]\tLoss 0.8865 (0.8881)\tAccuracy 65.039 (63.225)\n",
      "Epoch: [7][200/3057]\tLoss 0.8959 (0.8859)\tAccuracy 64.258 (63.339)\n",
      "Epoch: [7][300/3057]\tLoss 0.8741 (0.8873)\tAccuracy 64.062 (63.289)\n",
      "Epoch: [7][400/3057]\tLoss 0.8916 (0.8864)\tAccuracy 62.695 (63.342)\n",
      "Epoch: [7][500/3057]\tLoss 0.8842 (0.8861)\tAccuracy 63.867 (63.362)\n",
      "Epoch: [7][600/3057]\tLoss 0.8976 (0.8866)\tAccuracy 61.914 (63.317)\n",
      "Epoch: [7][700/3057]\tLoss 0.9104 (0.8870)\tAccuracy 62.207 (63.286)\n",
      "Epoch: [7][800/3057]\tLoss 0.9046 (0.8873)\tAccuracy 63.965 (63.288)\n",
      "Epoch: [7][900/3057]\tLoss 0.9003 (0.8874)\tAccuracy 62.891 (63.288)\n",
      "Epoch: [7][1000/3057]\tLoss 0.8854 (0.8872)\tAccuracy 64.648 (63.289)\n",
      "Epoch: [7][1100/3057]\tLoss 0.9442 (0.8873)\tAccuracy 61.328 (63.315)\n",
      "Epoch: [7][1200/3057]\tLoss 0.8896 (0.8877)\tAccuracy 62.988 (63.311)\n",
      "Epoch: [7][1300/3057]\tLoss 0.8777 (0.8879)\tAccuracy 63.184 (63.312)\n",
      "Epoch: [7][1400/3057]\tLoss 0.9387 (0.8880)\tAccuracy 59.863 (63.313)\n",
      "Epoch: [7][1500/3057]\tLoss 0.9357 (0.8876)\tAccuracy 61.230 (63.337)\n",
      "Epoch: [7][1600/3057]\tLoss 0.9230 (0.8875)\tAccuracy 62.109 (63.339)\n",
      "Epoch: [7][1700/3057]\tLoss 0.9085 (0.8873)\tAccuracy 60.156 (63.341)\n",
      "Epoch: [7][1800/3057]\tLoss 0.8844 (0.8873)\tAccuracy 60.742 (63.331)\n",
      "Epoch: [7][1900/3057]\tLoss 0.8671 (0.8871)\tAccuracy 64.453 (63.346)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][2000/3057]\tLoss 0.9028 (0.8869)\tAccuracy 62.012 (63.353)\n",
      "Epoch: [7][2100/3057]\tLoss 0.8261 (0.8869)\tAccuracy 66.211 (63.356)\n",
      "Epoch: [7][2200/3057]\tLoss 0.8977 (0.8869)\tAccuracy 62.402 (63.353)\n",
      "Epoch: [7][2300/3057]\tLoss 0.8765 (0.8869)\tAccuracy 63.477 (63.345)\n",
      "Epoch: [7][2400/3057]\tLoss 0.9095 (0.8869)\tAccuracy 62.207 (63.348)\n",
      "Epoch: [7][2500/3057]\tLoss 0.8224 (0.8868)\tAccuracy 63.965 (63.349)\n",
      "Epoch: [7][2600/3057]\tLoss 0.8899 (0.8867)\tAccuracy 64.160 (63.353)\n",
      "Epoch: [7][2700/3057]\tLoss 0.8790 (0.8866)\tAccuracy 64.551 (63.360)\n",
      "Epoch: [7][2800/3057]\tLoss 0.8412 (0.8864)\tAccuracy 66.797 (63.364)\n",
      "Epoch: [7][2900/3057]\tLoss 0.9311 (0.8864)\tAccuracy 60.352 (63.363)\n",
      "Epoch: [7][3000/3057]\tLoss 0.9009 (0.8864)\tAccuracy 63.086 (63.364)\n",
      "Dev in\t Loss (0.8752)\tAccuracy (63.830)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [8][0/3057]\tLoss 0.9032 (0.9032)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [8][100/3057]\tLoss 0.8777 (0.8832)\tAccuracy 63.184 (63.433)\n",
      "Epoch: [8][200/3057]\tLoss 0.8365 (0.8834)\tAccuracy 66.406 (63.518)\n",
      "Epoch: [8][300/3057]\tLoss 0.8860 (0.8824)\tAccuracy 64.258 (63.578)\n",
      "Epoch: [8][400/3057]\tLoss 0.8869 (0.8815)\tAccuracy 64.648 (63.599)\n",
      "Epoch: [8][500/3057]\tLoss 0.9124 (0.8816)\tAccuracy 62.402 (63.591)\n",
      "Epoch: [8][600/3057]\tLoss 0.8604 (0.8815)\tAccuracy 62.695 (63.584)\n",
      "Epoch: [8][700/3057]\tLoss 0.8574 (0.8818)\tAccuracy 64.453 (63.565)\n",
      "Epoch: [8][800/3057]\tLoss 0.8373 (0.8818)\tAccuracy 67.578 (63.553)\n",
      "Epoch: [8][900/3057]\tLoss 0.8836 (0.8816)\tAccuracy 62.500 (63.563)\n",
      "Epoch: [8][1000/3057]\tLoss 0.8713 (0.8819)\tAccuracy 63.867 (63.566)\n",
      "Epoch: [8][1100/3057]\tLoss 0.8895 (0.8820)\tAccuracy 65.234 (63.567)\n",
      "Epoch: [8][1200/3057]\tLoss 0.8874 (0.8817)\tAccuracy 62.695 (63.577)\n",
      "Epoch: [8][1300/3057]\tLoss 0.8331 (0.8817)\tAccuracy 65.234 (63.584)\n",
      "Epoch: [8][1400/3057]\tLoss 0.8954 (0.8815)\tAccuracy 63.379 (63.589)\n",
      "Epoch: [8][1500/3057]\tLoss 0.8714 (0.8816)\tAccuracy 62.695 (63.578)\n",
      "Epoch: [8][1600/3057]\tLoss 0.8777 (0.8816)\tAccuracy 62.891 (63.568)\n",
      "Epoch: [8][1700/3057]\tLoss 0.8822 (0.8815)\tAccuracy 64.648 (63.580)\n",
      "Epoch: [8][1800/3057]\tLoss 0.8752 (0.8817)\tAccuracy 62.695 (63.563)\n",
      "Epoch: [8][1900/3057]\tLoss 0.8541 (0.8816)\tAccuracy 65.625 (63.560)\n",
      "Epoch: [8][2000/3057]\tLoss 0.9483 (0.8814)\tAccuracy 62.402 (63.579)\n",
      "Epoch: [8][2100/3057]\tLoss 0.8814 (0.8815)\tAccuracy 63.672 (63.584)\n",
      "Epoch: [8][2200/3057]\tLoss 0.8978 (0.8815)\tAccuracy 64.453 (63.583)\n",
      "Epoch: [8][2300/3057]\tLoss 0.9118 (0.8813)\tAccuracy 62.695 (63.590)\n",
      "Epoch: [8][2400/3057]\tLoss 0.9273 (0.8814)\tAccuracy 61.621 (63.588)\n",
      "Epoch: [8][2500/3057]\tLoss 0.8599 (0.8814)\tAccuracy 65.625 (63.588)\n",
      "Epoch: [8][2600/3057]\tLoss 0.9084 (0.8812)\tAccuracy 62.402 (63.588)\n",
      "Epoch: [8][2700/3057]\tLoss 0.8643 (0.8812)\tAccuracy 64.648 (63.590)\n",
      "Epoch: [8][2800/3057]\tLoss 0.8899 (0.8811)\tAccuracy 62.988 (63.595)\n",
      "Epoch: [8][2900/3057]\tLoss 0.8706 (0.8811)\tAccuracy 62.500 (63.593)\n",
      "Epoch: [8][3000/3057]\tLoss 0.8393 (0.8809)\tAccuracy 66.504 (63.602)\n",
      "Dev in\t Loss (0.8722)\tAccuracy (64.030)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [9][0/3057]\tLoss 0.8788 (0.8788)\tAccuracy 63.477 (63.477)\n",
      "Epoch: [9][100/3057]\tLoss 0.8785 (0.8777)\tAccuracy 63.574 (63.712)\n",
      "Epoch: [9][200/3057]\tLoss 0.8559 (0.8762)\tAccuracy 62.988 (63.791)\n",
      "Epoch: [9][300/3057]\tLoss 0.8718 (0.8757)\tAccuracy 63.672 (63.812)\n",
      "Epoch: [9][400/3057]\tLoss 0.8965 (0.8768)\tAccuracy 61.621 (63.780)\n",
      "Epoch: [9][500/3057]\tLoss 0.8459 (0.8768)\tAccuracy 65.723 (63.776)\n",
      "Epoch: [9][600/3057]\tLoss 0.9132 (0.8769)\tAccuracy 62.891 (63.773)\n",
      "Epoch: [9][700/3057]\tLoss 0.8573 (0.8769)\tAccuracy 63.867 (63.760)\n",
      "Epoch: [9][800/3057]\tLoss 0.9015 (0.8765)\tAccuracy 62.695 (63.799)\n",
      "Epoch: [9][900/3057]\tLoss 0.8685 (0.8766)\tAccuracy 63.477 (63.781)\n",
      "Epoch: [9][1000/3057]\tLoss 0.8815 (0.8767)\tAccuracy 63.867 (63.765)\n",
      "Epoch: [9][1100/3057]\tLoss 0.9138 (0.8768)\tAccuracy 62.402 (63.767)\n",
      "Epoch: [9][1200/3057]\tLoss 0.8407 (0.8766)\tAccuracy 66.016 (63.786)\n",
      "Epoch: [9][1300/3057]\tLoss 0.8589 (0.8765)\tAccuracy 62.695 (63.783)\n",
      "Epoch: [9][1400/3057]\tLoss 0.8972 (0.8770)\tAccuracy 64.453 (63.763)\n",
      "Epoch: [9][1500/3057]\tLoss 0.8641 (0.8769)\tAccuracy 64.160 (63.768)\n",
      "Epoch: [9][1600/3057]\tLoss 0.8808 (0.8769)\tAccuracy 64.160 (63.769)\n",
      "Epoch: [9][1700/3057]\tLoss 0.8520 (0.8766)\tAccuracy 64.746 (63.788)\n",
      "Epoch: [9][1800/3057]\tLoss 0.8567 (0.8765)\tAccuracy 63.477 (63.798)\n",
      "Epoch: [9][1900/3057]\tLoss 0.8458 (0.8763)\tAccuracy 65.625 (63.815)\n",
      "Epoch: [9][2000/3057]\tLoss 0.9115 (0.8763)\tAccuracy 61.914 (63.815)\n",
      "Epoch: [9][2100/3057]\tLoss 0.8693 (0.8764)\tAccuracy 63.770 (63.812)\n",
      "Epoch: [9][2200/3057]\tLoss 0.8537 (0.8759)\tAccuracy 65.430 (63.831)\n",
      "Epoch: [9][2300/3057]\tLoss 0.8690 (0.8758)\tAccuracy 63.184 (63.837)\n",
      "Epoch: [9][2400/3057]\tLoss 0.8770 (0.8757)\tAccuracy 62.891 (63.845)\n",
      "Epoch: [9][2500/3057]\tLoss 0.8563 (0.8758)\tAccuracy 64.746 (63.844)\n",
      "Epoch: [9][2600/3057]\tLoss 0.8919 (0.8759)\tAccuracy 62.305 (63.845)\n",
      "Epoch: [9][2700/3057]\tLoss 0.8662 (0.8758)\tAccuracy 63.770 (63.844)\n",
      "Epoch: [9][2800/3057]\tLoss 0.8469 (0.8758)\tAccuracy 65.430 (63.842)\n",
      "Epoch: [9][2900/3057]\tLoss 0.8967 (0.8757)\tAccuracy 64.844 (63.855)\n",
      "Epoch: [9][3000/3057]\tLoss 0.8731 (0.8756)\tAccuracy 65.625 (63.857)\n",
      "Dev in\t Loss (0.8660)\tAccuracy (64.322)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # train for one epoch\n",
    "    print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "    train(train_dl, model, criterion, optimizer, epoch, device)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    eval(dev_in_dl, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
