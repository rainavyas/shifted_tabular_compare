{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rtdl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.543321e+09</td>\n",
       "      <td>26.968800</td>\n",
       "      <td>-99.248901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-17.526443</td>\n",
       "      <td>14.613571</td>\n",
       "      <td>754.263405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.600006</td>\n",
       "      <td>-2.750006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.538776e+09</td>\n",
       "      <td>29.374201</td>\n",
       "      <td>-100.927002</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>297.0</td>\n",
       "      <td>41.531032</td>\n",
       "      <td>26.992143</td>\n",
       "      <td>733.117168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.600006</td>\n",
       "      <td>17.950006</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552115e+09</td>\n",
       "      <td>22.149599</td>\n",
       "      <td>113.592003</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43.916531</td>\n",
       "      <td>18.842143</td>\n",
       "      <td>761.571076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233978</td>\n",
       "      <td>21.450006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.549566e+09</td>\n",
       "      <td>34.678699</td>\n",
       "      <td>-86.684799</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.240955</td>\n",
       "      <td>8.303571</td>\n",
       "      <td>747.524910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>16.150018</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.552910e+09</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>41.966667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.394660</td>\n",
       "      <td>6.451429</td>\n",
       "      <td>753.168113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>3.150018</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1.543321e+09      26.968800      -99.248901               2.0   \n",
       "1  1.538776e+09      29.374201     -100.927002              31.0   \n",
       "2  1.552115e+09      22.149599      113.592003              17.0   \n",
       "3  1.549566e+09      34.678699      -86.684799              24.0   \n",
       "4  1.552910e+09      46.066667       41.966667               9.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0              0.0             dry                  127.0     -17.526443   \n",
       "1             20.0  mild temperate                  297.0      41.531032   \n",
       "2             10.0  mild temperate                   -1.0      43.916531   \n",
       "3             20.0  mild temperate                  193.0      40.240955   \n",
       "4             20.0             dry                   90.0      30.394660   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            14.613571        754.263405  ...                0.0   \n",
       "1            26.992143        733.117168  ...                0.0   \n",
       "2            18.842143        761.571076  ...                0.0   \n",
       "3             8.303571        747.524910  ...                0.0   \n",
       "4             6.451429        753.168113  ...                0.0   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0             -2.600006             -2.750006   \n",
       "1                0.0             -0.600006             17.950006   \n",
       "2                0.0             -0.233978             21.450006   \n",
       "3                0.0              0.059448             16.150018   \n",
       "4                0.0              0.400024              3.150018   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              0.0                              0.0  \n",
       "1                            -12.0                             11.0  \n",
       "2                              1.0                              8.0  \n",
       "3                            -58.0                             41.0  \n",
       "4                             18.0                             92.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "train_path = '../../zipped/train.csv'\n",
    "dev_in_path = '../../zipped/dev_in.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539162000</td>\n",
       "      <td>-40.350000</td>\n",
       "      <td>-9.880000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>tropical</td>\n",
       "      <td>-843.0</td>\n",
       "      <td>31.782490</td>\n",
       "      <td>10.070714</td>\n",
       "      <td>765.631228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505035</td>\n",
       "      <td>2.647577</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1545006600</td>\n",
       "      <td>53.421299</td>\n",
       "      <td>-6.270070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-59.691521</td>\n",
       "      <td>7.005000</td>\n",
       "      <td>752.897615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400024</td>\n",
       "      <td>1.249994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540094400</td>\n",
       "      <td>-19.757700</td>\n",
       "      <td>63.361000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>dry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.250889</td>\n",
       "      <td>23.327143</td>\n",
       "      <td>763.115016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>21.050012</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1552611600</td>\n",
       "      <td>35.245899</td>\n",
       "      <td>47.009201</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>-23.755615</td>\n",
       "      <td>3.109286</td>\n",
       "      <td>609.419333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69672</td>\n",
       "      <td>5.1653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.349982</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1545631200</td>\n",
       "      <td>26.633333</td>\n",
       "      <td>118.150000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>210.0</td>\n",
       "      <td>33.040438</td>\n",
       "      <td>12.172143</td>\n",
       "      <td>734.678037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102081</td>\n",
       "      <td>11.513879</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1539162000     -40.350000       -9.880000              11.0   \n",
       "1  1545006600      53.421299       -6.270070               4.0   \n",
       "2  1540094400     -19.757700       63.361000              26.0   \n",
       "3  1552611600      35.245899       47.009201               5.0   \n",
       "4  1545631200      26.633333      118.150000              14.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0               10        tropical                 -843.0      31.782490   \n",
       "1               10  mild temperate                   67.0     -59.691521   \n",
       "2               10             dry                    6.0      35.250889   \n",
       "3               10  mild temperate                 1390.0     -23.755615   \n",
       "4               20  mild temperate                  210.0      33.040438   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            10.070714        765.631228  ...            0.00000   \n",
       "1             7.005000        752.897615  ...            0.00000   \n",
       "2            23.327143        763.115016  ...            0.00000   \n",
       "3             3.109286        609.419333  ...            1.69672   \n",
       "4            12.172143        734.678037  ...            0.00000   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0             0.0000                0.0           0.000000                0.0   \n",
       "1             0.0000                0.0           0.000000                0.0   \n",
       "2             0.0000                0.0           0.000000                0.0   \n",
       "3             5.1653                0.0           0.000049                0.0   \n",
       "4             0.0000                0.0           0.000000                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0              0.505035              2.647577   \n",
       "1                0.0             -0.400024              1.249994   \n",
       "2                0.0              0.100006             21.050012   \n",
       "3                0.0             -1.500000             -0.349982   \n",
       "4                0.0              0.102081             11.513879   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              2.0                              2.0  \n",
       "1                              0.0                              0.0  \n",
       "2                             -1.0                              1.0  \n",
       "3                            -12.0                             81.0  \n",
       "4                            -15.0                             83.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_in = pd.read_csv(dev_in_path)\n",
    "df_dev_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_out_path = '../../data/dev_out.csv'\n",
    "eval_in_path = '../../data/test_in.csv'\n",
    "eval_out_path = '../../data/test_out.csv'\n",
    "\n",
    "df_dev_out = pd.read_csv(dev_out_path)\n",
    "df_eval_in = pd.read_csv(eval_in_path)\n",
    "df_eval_out = pd.read_csv(eval_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact_cwsm_class', 'climate', 'cmc_available', 'gfs_available', 'gfs_soil_temperature_available', 'gfs_timedelta_s', 'wrf_available']\n"
     ]
    }
   ],
   "source": [
    "# Identify the categorical features\n",
    "cat_features = []\n",
    "for col in df_dev_in:\n",
    "    values = df_dev_in[col].tolist()\n",
    "    unique = list(dict.fromkeys(values))\n",
    "    if len(unique) < 20:\n",
    "        cat_features.append(col)\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1545219635.2602534, 27.3491997995972, -19.454721235367906, 15.030736293991083, 0.0, 'mild temperate', 309.93658796685, -2.7249874731371273, 15.053651434869764, 731.2756530851661, 289.1659257771938, 0.0513848381221949, 287.04881832634976, 287.0853175734476, 287.0339327353252, 258.9922501121575, 274.97475431188, 282.77351197349384, 285.8909051108904, 281.3276019215079, 7.660611531165116, 5.534873822269684, 14.704511863943937, 12.971739936778564, 8.78866233485156, 7.2775056043593676, 0.009529923266778687, 0.00859610917297107, 6.413124162323838, 0.2673820249969054, 0.027512247376225554, 0.008222988603064724, 3.866966535018241e-05, -0.0020003342605871715, -0.05948973513452053, 10.42531664950694, 5.2929354486362215, 1.8376276146288066, 0.4768480677913728, -0.09701087752828826, -0.14489588205685547, 0.22814633531193007, 0.2219977889627698, 0.30237136633108197, 0.18710502254215602, 97345.58898593165, 97344.2322319218, 101661.80541725569, 137.95607755299883, 5728.521789532874, 3094.1520088604207, 1504.0103447668691, 797.3523991534046, 37.07459687934277, 1.0, 49.846809128188646, 0.1397615836326275, 3193.5639279354186, 7.875858105871922, 6.318132459416767e-05, 1.0, 0.7377752698462914, 1.4802979068821847e-07, 44.060568770740154, 65.5584417745946, 21.504211618918216, 0.12521102946095294, 731.2233402176113, 0.008033159667266226, -1819.1629409387926, 1.0, -67.28908852176293, -61.45628742576919, -55.78256429751954, -48.40214544214997, -40.239168086804234, -32.42869414585041, -25.500304955545896, -19.46492327470662, -64.14897479374763, -14.198140237399796, -9.559197665244577, -5.41065208747797, -1.7061806962327069, -67.16019146882202, 1.6164132948853693, 4.626240268496011, 7.342803033488016, 9.823743835990618, 12.211598927309758, 13.416417220454605, 14.645629188839976, 15.883642604926143, 15.470014013486876, 0.04935516746916531, 15.483820810290512, 15.519105578698078, 0.0, 38.702409655095366, 18.238931974809194, 16.836185354724595, -0.01449744864394827, -0.04546247978039495, 3.7423347274135303, 1.0, 287.9381975660448, 287.95573134943953, 97994.65417635812, 0.7362492437923865, -0.05505970029976019, -0.08985226965162621, 0.12765691011045083, 0.004114918452075356, 0.0011533477698721, 0.0, 287.9381975660448, 0.017533783394746115, 0.40059827557247835, 6.813722437896308, 0.016303617495967773, 0.28368564249287337, 0.0017981805217585445, 0.029310427897984142, 0.0005846442774275127, 0.008807632880492246, 0.013054502087814274, 7.888782940886862, 0.0073836321184068306, 18.246277597971417])\n"
     ]
    }
   ],
   "source": [
    "# !pip install scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "nan_replacements = {}\n",
    "for col in df_train:\n",
    "    if col in cat_features:\n",
    "        nan_replacements[col] = stats.mode(np.asarray(df_train[col].tolist()))[0][0]\n",
    "        # print(nan_replacements[col])\n",
    "    else:\n",
    "        nan_replacements[col] = np.mean(np.asarray(df_train[col].dropna().tolist()))\n",
    "print(nan_replacements.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nans\n",
    "for col in df_train:\n",
    "    df_train[col] = df_train[col].fillna(nan_replacements[col])\n",
    "    df_dev_in[col] = df_dev_in[col].fillna(nan_replacements[col])\n",
    "    df_dev_out[col] = df_dev_out[col].fillna(nan_replacements[col])\n",
    "    df_eval_in[col] = df_eval_in[col].fillna(nan_replacements[col])\n",
    "    df_eval_out[col] = df_eval_out[col].fillna(nan_replacements[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    X: Dict[str, np.ndarray], normalization: str, seed: int, noise: float = 1e-3\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    # X ~ {'train': <train_size x n_features>, 'val': <val_size x n_features>, 'test': <test_size x n_features>}\n",
    "    X_train = X['train']\n",
    "    if normalization == 'standard':\n",
    "        normalizer = sklearn.preprocessing.StandardScaler()\n",
    "    elif normalization == 'quantile':\n",
    "        normalizer = sklearn.preprocessing.QuantileTransformer(\n",
    "            output_distribution='normal',\n",
    "            n_quantiles=max(min(X['train'].shape[0] // 30, 1000), 10),\n",
    "            subsample=1e9,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        if noise:\n",
    "            X_train = X_train.copy()\n",
    "            stds = np.std(X_train, axis=0, keepdims=True)\n",
    "            noise_std = noise / np.maximum(stds, noise)\n",
    "            X_train += noise_std * np.random.default_rng(seed).standard_normal(\n",
    "                X_train.shape\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f'unknown normalization: {normalization}')\n",
    "    normalizer.fit(X_train)\n",
    "    return {k: normalizer.transform(v) for k, v in X.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise using train data stats\n",
    "# Quantile normalisation is used (maps to a normal distribution)\n",
    "df_test = df_eval_out\n",
    "X_train_np = np.asarray(df_train.iloc[:,6:])\n",
    "X_test_np = np.asarray(df_test.iloc[:,6:])\n",
    "X = {'train': X_train_np, 'test': X_test_np}\n",
    "X = normalize(X, normalization='quantile', seed=seed)\n",
    "X_test_np = X['test']\n",
    "X_test = torch.FloatTensor(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess into tensors\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_lab_to_ind(data_df):\n",
    "    '''\n",
    "    Prepare a label to index map\n",
    "    '''\n",
    "    y_fact = set(list(data_df['fact_cwsm_class']))\n",
    "    lab_to_ind = {}\n",
    "    for i, lab in enumerate(y_fact):\n",
    "        lab_to_ind[lab] = i\n",
    "    return lab_to_ind\n",
    "\n",
    "lab_to_ind = get_lab_to_ind(df_train)\n",
    "batch_size = 256\n",
    "\n",
    "# Test\n",
    "y_test = df_test['fact_cwsm_class']\n",
    "y_test = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_test]))\n",
    "\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got CUDA!\n"
     ]
    }
   ],
   "source": [
    "# Get the device\n",
    "\n",
    "def get_default_device():\n",
    "#     # Force cpu for now\n",
    "#     return torch.device('cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Got CUDA!\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"No CUDA found\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTTransformer(\n",
       "  (feature_tokenizer): FeatureTokenizer(\n",
       "    (num_tokenizer): NumericalFeatureTokenizer()\n",
       "  )\n",
       "  (cls_token): CLSToken()\n",
       "  (transformer): Transformer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): FFN(\n",
       "          (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (head): Head(\n",
       "      (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): ReLU()\n",
       "      (linear): Linear(in_features=192, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Feature Transformer Model\n",
    "\n",
    "model = rtdl.FTTransformer.make_default(\n",
    "    n_num_features=X_test.shape[1],\n",
    "    cat_cardinalities=None,\n",
    "    last_layer_query_idx=[-1],\n",
    "    d_out=len(lab_to_ind)\n",
    ")\n",
    "\n",
    "model_path = f'./trained_models/FTTransformer/model{seed}.th'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline to apply model\n",
    "def apply_model(model, x_num, x_cat=None):\n",
    "    '''\n",
    "    FTTransformer expects numerical and categorical inputs separately\n",
    "    '''\n",
    "    return model(x_num, x_cat) if isinstance(model, rtdl.FTTransformer) else model(x_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(val_loader, model, device):\n",
    "    '''\n",
    "    Run evaluation\n",
    "    '''\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for i, (x, target) in enumerate(val_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = apply_model(model, x)\n",
    "        logits = logits.detach().cpu().numpy().tolist()\n",
    "        preds += logits\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def metric_accuracy(preds, targets):\n",
    "    preds = np.asarray(preds)\n",
    "    targets = np.asarray(targets)\n",
    "    pred_inds = np.argmax(np.asarray(preds), axis=1)\n",
    "    return accuracy_score(targets, pred_inds)\n",
    "\n",
    "def get_avg_f1(preds, labels):\n",
    "    '''\n",
    "    Calculate one-vs-all f1 score per class\n",
    "    Return average of f1 scores over all classes\n",
    "    preds: [num_samples x num_classes]\n",
    "    '''\n",
    "    f1s = []\n",
    "    label_inds = labels\n",
    "    class_inds_to_check = list(set(label_inds))\n",
    "\n",
    "    for class_ind_to_check in class_inds_to_check:\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for pred, lab_ind in zip(preds, label_inds):\n",
    "            y_pred.append(pred[class_ind_to_check])\n",
    "            if lab_ind == class_ind_to_check:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "        f_scores = (2*precision*recall)/(precision+recall)\n",
    "        f_scores_clean = f_scores[np.logical_not(np.isnan(f_scores))]\n",
    "        f1s.append(np.amax(f_scores_clean))\n",
    "    return np.mean(np.asarray(f1s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "preds = eval(test_dl, model, device)\n",
    "targets = [lab_to_ind[lab] for lab in df_test['fact_cwsm_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './predictions/'\n",
    "dataset = 'eval_out/'\n",
    "# save targets\n",
    "np.save(out_dir+dataset+'targets.npy', np.asarray(targets))\n",
    "# save predictions to file\n",
    "np.save(out_dir+dataset+str(seed)+'.npy', np.asarray(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miproj/4thyr.oct2019/vr311/venv_tabTrans/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/miproj/4thyr.oct2019/vr311/venv_tabTrans/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/miproj/4thyr.oct2019/vr311/venv_tabTrans/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/miproj/4thyr.oct2019/vr311/venv_tabTrans/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/miproj/4thyr.oct2019/vr311/venv_tabTrans/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642073024802905\n",
      "0.2876467428294247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miproj/4thyr.oct2019/vr311/venv_tabTrans/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "accuracy = metric_accuracy(preds, targets)\n",
    "f_macro = get_avg_f1(preds, targets)\n",
    "print(accuracy)\n",
    "print(f_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
