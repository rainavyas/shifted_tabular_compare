{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.543321e+09</td>\n",
       "      <td>26.968800</td>\n",
       "      <td>-99.248901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-17.526443</td>\n",
       "      <td>14.613571</td>\n",
       "      <td>754.263405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.600006</td>\n",
       "      <td>-2.750006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.538776e+09</td>\n",
       "      <td>29.374201</td>\n",
       "      <td>-100.927002</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>297.0</td>\n",
       "      <td>41.531032</td>\n",
       "      <td>26.992143</td>\n",
       "      <td>733.117168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.600006</td>\n",
       "      <td>17.950006</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552115e+09</td>\n",
       "      <td>22.149599</td>\n",
       "      <td>113.592003</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43.916531</td>\n",
       "      <td>18.842143</td>\n",
       "      <td>761.571076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233978</td>\n",
       "      <td>21.450006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.549566e+09</td>\n",
       "      <td>34.678699</td>\n",
       "      <td>-86.684799</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.240955</td>\n",
       "      <td>8.303571</td>\n",
       "      <td>747.524910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>16.150018</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.552910e+09</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>41.966667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.394660</td>\n",
       "      <td>6.451429</td>\n",
       "      <td>753.168113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>3.150018</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1.543321e+09      26.968800      -99.248901               2.0   \n",
       "1  1.538776e+09      29.374201     -100.927002              31.0   \n",
       "2  1.552115e+09      22.149599      113.592003              17.0   \n",
       "3  1.549566e+09      34.678699      -86.684799              24.0   \n",
       "4  1.552910e+09      46.066667       41.966667               9.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0              0.0             dry                  127.0     -17.526443   \n",
       "1             20.0  mild temperate                  297.0      41.531032   \n",
       "2             10.0  mild temperate                   -1.0      43.916531   \n",
       "3             20.0  mild temperate                  193.0      40.240955   \n",
       "4             20.0             dry                   90.0      30.394660   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            14.613571        754.263405  ...                0.0   \n",
       "1            26.992143        733.117168  ...                0.0   \n",
       "2            18.842143        761.571076  ...                0.0   \n",
       "3             8.303571        747.524910  ...                0.0   \n",
       "4             6.451429        753.168113  ...                0.0   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0             -2.600006             -2.750006   \n",
       "1                0.0             -0.600006             17.950006   \n",
       "2                0.0             -0.233978             21.450006   \n",
       "3                0.0              0.059448             16.150018   \n",
       "4                0.0              0.400024              3.150018   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              0.0                              0.0  \n",
       "1                            -12.0                             11.0  \n",
       "2                              1.0                              8.0  \n",
       "3                            -58.0                             41.0  \n",
       "4                             18.0                             92.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "train_path = '../data/train.csv'\n",
    "dev_in_path = '../data/dev_in.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1539162000</td>\n",
       "      <td>-40.350000</td>\n",
       "      <td>-9.880000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>tropical</td>\n",
       "      <td>-843.0</td>\n",
       "      <td>31.782490</td>\n",
       "      <td>10.070714</td>\n",
       "      <td>765.631228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505035</td>\n",
       "      <td>2.647577</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1545006600</td>\n",
       "      <td>53.421299</td>\n",
       "      <td>-6.270070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-59.691521</td>\n",
       "      <td>7.005000</td>\n",
       "      <td>752.897615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400024</td>\n",
       "      <td>1.249994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540094400</td>\n",
       "      <td>-19.757700</td>\n",
       "      <td>63.361000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>dry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.250889</td>\n",
       "      <td>23.327143</td>\n",
       "      <td>763.115016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>21.050012</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1552611600</td>\n",
       "      <td>35.245899</td>\n",
       "      <td>47.009201</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>-23.755615</td>\n",
       "      <td>3.109286</td>\n",
       "      <td>609.419333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69672</td>\n",
       "      <td>5.1653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.349982</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1545631200</td>\n",
       "      <td>26.633333</td>\n",
       "      <td>118.150000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>210.0</td>\n",
       "      <td>33.040438</td>\n",
       "      <td>12.172143</td>\n",
       "      <td>734.678037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102081</td>\n",
       "      <td>11.513879</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1539162000     -40.350000       -9.880000              11.0   \n",
       "1  1545006600      53.421299       -6.270070               4.0   \n",
       "2  1540094400     -19.757700       63.361000              26.0   \n",
       "3  1552611600      35.245899       47.009201               5.0   \n",
       "4  1545631200      26.633333      118.150000              14.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0               10        tropical                 -843.0      31.782490   \n",
       "1               10  mild temperate                   67.0     -59.691521   \n",
       "2               10             dry                    6.0      35.250889   \n",
       "3               10  mild temperate                 1390.0     -23.755615   \n",
       "4               20  mild temperate                  210.0      33.040438   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            10.070714        765.631228  ...            0.00000   \n",
       "1             7.005000        752.897615  ...            0.00000   \n",
       "2            23.327143        763.115016  ...            0.00000   \n",
       "3             3.109286        609.419333  ...            1.69672   \n",
       "4            12.172143        734.678037  ...            0.00000   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0             0.0000                0.0           0.000000                0.0   \n",
       "1             0.0000                0.0           0.000000                0.0   \n",
       "2             0.0000                0.0           0.000000                0.0   \n",
       "3             5.1653                0.0           0.000049                0.0   \n",
       "4             0.0000                0.0           0.000000                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0              0.505035              2.647577   \n",
       "1                0.0             -0.400024              1.249994   \n",
       "2                0.0              0.100006             21.050012   \n",
       "3                0.0             -1.500000             -0.349982   \n",
       "4                0.0              0.102081             11.513879   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              2.0                              2.0  \n",
       "1                              0.0                              0.0  \n",
       "2                             -1.0                              1.0  \n",
       "3                            -12.0                             81.0  \n",
       "4                            -15.0                             83.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_in = pd.read_csv(dev_in_path)\n",
    "df_dev_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact_cwsm_class', 'climate', 'cmc_available', 'gfs_available', 'gfs_soil_temperature_available', 'gfs_timedelta_s', 'wrf_available']\n"
     ]
    }
   ],
   "source": [
    "# Identify the categorical features\n",
    "cat_features = []\n",
    "for col in df_dev_in:\n",
    "    values = df_dev_in[col].tolist()\n",
    "    unique = list(dict.fromkeys(values))\n",
    "    if len(unique) < 20:\n",
    "        cat_features.append(col)\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1545219635.2602534, 27.3491997995972, -19.454721235367906, 15.030736293991083, 0.0, 'mild temperate', 309.93658796685, -2.7249874731371273, 15.053651434869764, 731.2756530851661, 289.1659257771938, 0.0513848381221949, 287.04881832634976, 287.0853175734476, 287.0339327353252, 258.9922501121575, 274.97475431188, 282.77351197349384, 285.8909051108904, 281.3276019215079, 7.660611531165116, 5.534873822269684, 14.704511863943937, 12.971739936778564, 8.78866233485156, 7.2775056043593676, 0.009529923266778687, 0.00859610917297107, 6.413124162323838, 0.2673820249969054, 0.027512247376225554, 0.008222988603064724, 3.866966535018241e-05, -0.0020003342605871715, -0.05948973513452053, 10.42531664950694, 5.2929354486362215, 1.8376276146288066, 0.4768480677913728, -0.09701087752828826, -0.14489588205685547, 0.22814633531193007, 0.2219977889627698, 0.30237136633108197, 0.18710502254215602, 97345.58898593165, 97344.2322319218, 101661.80541725569, 137.95607755299883, 5728.521789532874, 3094.1520088604207, 1504.0103447668691, 797.3523991534046, 37.07459687934277, 1.0, 49.846809128188646, 0.1397615836326275, 3193.5639279354186, 7.875858105871922, 6.318132459416767e-05, 1.0, 0.7377752698462914, 1.4802979068821847e-07, 44.060568770740154, 65.5584417745946, 21.504211618918216, 0.12521102946095294, 731.2233402176113, 0.008033159667266226, -1819.1629409387926, 1.0, -67.28908852176293, -61.45628742576919, -55.78256429751954, -48.40214544214997, -40.239168086804234, -32.42869414585041, -25.500304955545896, -19.46492327470662, -64.14897479374763, -14.198140237399796, -9.559197665244577, -5.41065208747797, -1.7061806962327069, -67.16019146882202, 1.6164132948853693, 4.626240268496011, 7.342803033488016, 9.823743835990618, 12.211598927309758, 13.416417220454605, 14.645629188839976, 15.883642604926143, 15.470014013486876, 0.04935516746916531, 15.483820810290512, 15.519105578698078, 0.0, 38.702409655095366, 18.238931974809194, 16.836185354724595, -0.01449744864394827, -0.04546247978039495, 3.7423347274135303, 1.0, 287.9381975660448, 287.95573134943953, 97994.65417635812, 0.7362492437923865, -0.05505970029976019, -0.08985226965162621, 0.12765691011045083, 0.004114918452075356, 0.0011533477698721, 0.0, 287.9381975660448, 0.017533783394746115, 0.40059827557247835, 6.813722437896308, 0.016303617495967773, 0.28368564249287337, 0.0017981805217585445, 0.029310427897984142, 0.0005846442774275127, 0.008807632880492246, 0.013054502087814274, 7.888782940886862, 0.0073836321184068306, 18.246277597971417])\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "nan_replacements = {}\n",
    "for col in df_train:\n",
    "    if col in cat_features:\n",
    "        nan_replacements[col] = stats.mode(np.asarray(df_train[col].tolist()))[0][0]\n",
    "        # print(nan_replacements[col])\n",
    "    else:\n",
    "        nan_replacements[col] = np.mean(np.asarray(df_train[col].dropna().tolist()))\n",
    "print(nan_replacements.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nans in train and dev\n",
    "for col in df_train:\n",
    "    df_train[col] = df_train[col].fillna(nan_replacements[col])\n",
    "    df_dev_in[col] = df_dev_in[col].fillna(nan_replacements[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    X: Dict[str, np.ndarray], normalization: str, seed: int, noise: float = 1e-3\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    # X ~ {'train': <train_size x n_features>, 'val': <val_size x n_features>, 'test': <test_size x n_features>}\n",
    "    X_train = X['train']\n",
    "    if normalization == 'standard':\n",
    "        normalizer = sklearn.preprocessing.StandardScaler()\n",
    "    elif normalization == 'quantile':\n",
    "        normalizer = sklearn.preprocessing.QuantileTransformer(\n",
    "            output_distribution='normal',\n",
    "            n_quantiles=max(min(X['train'].shape[0] // 30, 1000), 10),\n",
    "            subsample=1e9,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        if noise:\n",
    "            X_train = X_train.copy()\n",
    "            stds = np.std(X_train, axis=0, keepdims=True)\n",
    "            noise_std = noise / np.maximum(stds, noise)\n",
    "            X_train += noise_std * np.random.default_rng(seed).standard_normal(\n",
    "                X_train.shape\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f'unknown normalization: {normalization}')\n",
    "    normalizer.fit(X_train)\n",
    "    return {k: normalizer.transform(v) for k, v in X.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise using train data stats\n",
    "# Quantile normalisation is used (maps to a normal distribution)\n",
    "X_train_np = np.asarray(df_train.iloc[:,6:])\n",
    "X_dev_in_np = np.asarray(df_dev_in.iloc[:,6:])\n",
    "X = {'train': X_train_np, 'dev_in': X_dev_in_np}\n",
    "X = normalize(X, normalization='quantile', seed=seed)\n",
    "X_train_np = X['train']\n",
    "X_dev_in_np = X['dev_in']\n",
    "\n",
    "X_train = torch.FloatTensor(X_train_np)\n",
    "X_dev_in = torch.FloatTensor(X_dev_in_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess into tensors\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_lab_to_ind(data_df):\n",
    "    '''\n",
    "    Prepare a label to index map\n",
    "    '''\n",
    "    y_fact = set(list(data_df['fact_cwsm_class']))\n",
    "    lab_to_ind = {}\n",
    "    for i, lab in enumerate(y_fact):\n",
    "        lab_to_ind[lab] = i\n",
    "    return lab_to_ind\n",
    "\n",
    "lab_to_ind = get_lab_to_ind(df_train)\n",
    "batch_size = 1024\n",
    "\n",
    "# Train\n",
    "y_train = np.asarray(df_train['fact_cwsm_class'])\n",
    "y_train = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_train]))\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Dev in\n",
    "y_dev_in = df_dev_in['fact_cwsm_class']\n",
    "y_dev_in = torch.LongTensor(np.asarray([lab_to_ind[lab] for lab in y_dev_in]))\n",
    "\n",
    "dev_in_ds = TensorDataset(X_dev_in, y_dev_in)\n",
    "dev_in_dl = DataLoader(dev_in_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA found\n"
     ]
    }
   ],
   "source": [
    "# Get the device\n",
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Got CUDA!\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"No CUDA found\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (predictor): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ResNetBlock(\n",
       "      (block): Sequential(\n",
       "        (0): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=123, out_features=256, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.25, inplace=False)\n",
       "        (4): Linear(in_features=256, out_features=123, bias=True)\n",
       "        (5): Dropout(p=0.25, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): BatchNorm1d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=123, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define ResNet model\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    '''\n",
    "    Residual Block\n",
    "    '''\n",
    "    def __init__(self, num_feats, layer_size, dropout_p):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features=num_feats),\n",
    "            nn.Linear(num_feats, layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(layer_size, num_feats),\n",
    "            nn.Dropout(dropout_p)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "        ResNet\n",
    "    '''\n",
    "    def __init__(self, num_feats=123, num_classes=9):\n",
    "        super().__init__()\n",
    "        \n",
    "        layer_size=256\n",
    "        dropout_p = 0.25\n",
    "        \n",
    "        self.predictor = nn.Sequential(\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            ResNetBlock(num_feats, layer_size, dropout_p),\n",
    "            nn.BatchNorm1d(num_features=num_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_feats, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.predictor(x)\n",
    "\n",
    "model = ResNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lr = 0.0001\n",
    "weight_decay = 0.9\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Function\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy_topk(output, target, k=1):\n",
    "    \"\"\"Computes the topk accuracy\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = torch.topk(output, k=k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "    res_total = 0\n",
    "    for curr_k in range(k):\n",
    "      curr_ind = pred[:,curr_k]\n",
    "      num_eq = torch.eq(curr_ind, target).sum()\n",
    "      acc = num_eq/len(output)\n",
    "      res_total += acc\n",
    "    return res_total*100\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, device, print_freq=100):\n",
    "    '''\n",
    "    Run one train epoch\n",
    "    '''\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (x, target) in enumerate(train_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # Backward pass and update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy_topk(logits.data, target)\n",
    "        accs.update(acc.item(), x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                    'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                    'Accuracy {prec.val:.3f} ({prec.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader),\n",
    "                      loss=losses, prec=accs))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(val_loader, model, criterion, device):\n",
    "    '''\n",
    "    Run evaluation\n",
    "    '''\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for i, (x, target) in enumerate(val_loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy_topk(logits.data, target)\n",
    "        accs.update(acc.item(), x.size(0))\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "\n",
    "    print('Dev in\\t Loss ({loss.avg:.4f})\\t'\n",
    "            'Accuracy ({prec.avg:.3f})\\n'.format(\n",
    "              loss=losses, prec=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-04\n",
      "Epoch: [0][0/3057]\tLoss 2.3062 (2.3062)\tAccuracy 2.637 (2.637)\n",
      "Epoch: [0][100/3057]\tLoss 1.4212 (1.7341)\tAccuracy 57.324 (41.865)\n",
      "Epoch: [0][200/3057]\tLoss 1.2208 (1.5311)\tAccuracy 58.301 (49.025)\n",
      "Epoch: [0][300/3057]\tLoss 1.1800 (1.4186)\tAccuracy 56.543 (51.789)\n",
      "Epoch: [0][400/3057]\tLoss 1.1091 (1.3443)\tAccuracy 57.617 (53.292)\n",
      "Epoch: [0][500/3057]\tLoss 1.0986 (1.2922)\tAccuracy 57.520 (54.243)\n",
      "Epoch: [0][600/3057]\tLoss 1.0341 (1.2532)\tAccuracy 59.863 (54.929)\n",
      "Epoch: [0][700/3057]\tLoss 1.0732 (1.2238)\tAccuracy 56.055 (55.388)\n",
      "Epoch: [0][800/3057]\tLoss 1.0079 (1.2001)\tAccuracy 60.059 (55.776)\n",
      "Epoch: [0][900/3057]\tLoss 1.0019 (1.1804)\tAccuracy 57.812 (56.099)\n",
      "Epoch: [0][1000/3057]\tLoss 0.9671 (1.1644)\tAccuracy 60.449 (56.368)\n",
      "Epoch: [0][1100/3057]\tLoss 0.9973 (1.1503)\tAccuracy 58.398 (56.598)\n",
      "Epoch: [0][1200/3057]\tLoss 0.9889 (1.1380)\tAccuracy 59.863 (56.817)\n",
      "Epoch: [0][1300/3057]\tLoss 1.0196 (1.1275)\tAccuracy 58.594 (57.004)\n",
      "Epoch: [0][1400/3057]\tLoss 0.9797 (1.1180)\tAccuracy 61.328 (57.176)\n",
      "Epoch: [0][1500/3057]\tLoss 0.9333 (1.1098)\tAccuracy 63.574 (57.324)\n",
      "Epoch: [0][1600/3057]\tLoss 1.0038 (1.1023)\tAccuracy 58.594 (57.449)\n",
      "Epoch: [0][1700/3057]\tLoss 1.0111 (1.0957)\tAccuracy 59.082 (57.557)\n",
      "Epoch: [0][1800/3057]\tLoss 0.9911 (1.0894)\tAccuracy 61.328 (57.677)\n",
      "Epoch: [0][1900/3057]\tLoss 1.0028 (1.0837)\tAccuracy 59.277 (57.785)\n",
      "Epoch: [0][2000/3057]\tLoss 0.9812 (1.0786)\tAccuracy 60.059 (57.885)\n",
      "Epoch: [0][2100/3057]\tLoss 0.9737 (1.0740)\tAccuracy 59.863 (57.968)\n",
      "Epoch: [0][2200/3057]\tLoss 1.0085 (1.0698)\tAccuracy 58.496 (58.039)\n",
      "Epoch: [0][2300/3057]\tLoss 0.9949 (1.0659)\tAccuracy 59.863 (58.111)\n",
      "Epoch: [0][2400/3057]\tLoss 1.0108 (1.0620)\tAccuracy 58.789 (58.192)\n",
      "Epoch: [0][2500/3057]\tLoss 0.9991 (1.0584)\tAccuracy 59.668 (58.267)\n",
      "Epoch: [0][2600/3057]\tLoss 0.9849 (1.0550)\tAccuracy 58.789 (58.332)\n",
      "Epoch: [0][2700/3057]\tLoss 0.9885 (1.0520)\tAccuracy 57.324 (58.377)\n",
      "Epoch: [0][2800/3057]\tLoss 0.9350 (1.0492)\tAccuracy 61.621 (58.424)\n",
      "Epoch: [0][2900/3057]\tLoss 0.9607 (1.0465)\tAccuracy 57.812 (58.482)\n",
      "Epoch: [0][3000/3057]\tLoss 0.9434 (1.0440)\tAccuracy 61.328 (58.532)\n",
      "Dev in\t Loss (0.9538)\tAccuracy (60.632)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [1][0/3057]\tLoss 0.9516 (0.9516)\tAccuracy 61.133 (61.133)\n",
      "Epoch: [1][100/3057]\tLoss 0.9981 (0.9685)\tAccuracy 59.473 (59.961)\n",
      "Epoch: [1][200/3057]\tLoss 0.9704 (0.9684)\tAccuracy 59.668 (59.957)\n",
      "Epoch: [1][300/3057]\tLoss 0.9354 (0.9673)\tAccuracy 60.938 (59.998)\n",
      "Epoch: [1][400/3057]\tLoss 1.0130 (0.9654)\tAccuracy 57.324 (60.088)\n",
      "Epoch: [1][500/3057]\tLoss 0.9805 (0.9656)\tAccuracy 58.691 (60.080)\n",
      "Epoch: [1][600/3057]\tLoss 0.9702 (0.9654)\tAccuracy 60.156 (60.090)\n",
      "Epoch: [1][700/3057]\tLoss 0.9345 (0.9648)\tAccuracy 63.965 (60.112)\n",
      "Epoch: [1][800/3057]\tLoss 0.9390 (0.9640)\tAccuracy 63.379 (60.158)\n",
      "Epoch: [1][900/3057]\tLoss 0.9568 (0.9638)\tAccuracy 60.352 (60.173)\n",
      "Epoch: [1][1000/3057]\tLoss 0.9431 (0.9635)\tAccuracy 60.645 (60.188)\n",
      "Epoch: [1][1100/3057]\tLoss 0.9559 (0.9628)\tAccuracy 59.668 (60.219)\n",
      "Epoch: [1][1200/3057]\tLoss 0.9663 (0.9628)\tAccuracy 59.961 (60.217)\n",
      "Epoch: [1][1300/3057]\tLoss 0.9746 (0.9629)\tAccuracy 60.645 (60.215)\n",
      "Epoch: [1][1400/3057]\tLoss 0.9356 (0.9628)\tAccuracy 60.938 (60.224)\n",
      "Epoch: [1][1500/3057]\tLoss 0.9448 (0.9625)\tAccuracy 63.086 (60.229)\n",
      "Epoch: [1][1600/3057]\tLoss 0.9659 (0.9623)\tAccuracy 58.887 (60.238)\n",
      "Epoch: [1][1700/3057]\tLoss 0.9682 (0.9621)\tAccuracy 59.961 (60.242)\n",
      "Epoch: [1][1800/3057]\tLoss 0.9601 (0.9618)\tAccuracy 59.375 (60.257)\n",
      "Epoch: [1][1900/3057]\tLoss 0.9424 (0.9616)\tAccuracy 61.328 (60.253)\n",
      "Epoch: [1][2000/3057]\tLoss 0.9332 (0.9615)\tAccuracy 62.500 (60.251)\n",
      "Epoch: [1][2100/3057]\tLoss 0.9444 (0.9612)\tAccuracy 58.594 (60.260)\n",
      "Epoch: [1][2200/3057]\tLoss 0.9706 (0.9608)\tAccuracy 59.180 (60.282)\n",
      "Epoch: [1][2300/3057]\tLoss 0.9266 (0.9606)\tAccuracy 61.816 (60.283)\n",
      "Epoch: [1][2400/3057]\tLoss 0.9586 (0.9602)\tAccuracy 58.105 (60.301)\n",
      "Epoch: [1][2500/3057]\tLoss 0.9712 (0.9601)\tAccuracy 58.008 (60.299)\n",
      "Epoch: [1][2600/3057]\tLoss 0.9284 (0.9600)\tAccuracy 60.742 (60.305)\n",
      "Epoch: [1][2700/3057]\tLoss 0.9920 (0.9598)\tAccuracy 57.031 (60.314)\n",
      "Epoch: [1][2800/3057]\tLoss 0.9327 (0.9595)\tAccuracy 59.668 (60.324)\n",
      "Epoch: [1][2900/3057]\tLoss 0.9647 (0.9592)\tAccuracy 60.254 (60.335)\n",
      "Epoch: [1][3000/3057]\tLoss 0.9445 (0.9588)\tAccuracy 60.547 (60.353)\n",
      "Dev in\t Loss (0.9389)\tAccuracy (61.246)\n",
      "\n",
      "current lr 1.00000e-04\n",
      "Epoch: [2][0/3057]\tLoss 0.9411 (0.9411)\tAccuracy 61.328 (61.328)\n",
      "Epoch: [2][100/3057]\tLoss 0.9603 (0.9508)\tAccuracy 62.012 (60.591)\n",
      "Epoch: [2][200/3057]\tLoss 0.9460 (0.9505)\tAccuracy 62.598 (60.623)\n",
      "Epoch: [2][300/3057]\tLoss 0.9614 (0.9489)\tAccuracy 60.645 (60.712)\n",
      "Epoch: [2][400/3057]\tLoss 0.9151 (0.9496)\tAccuracy 62.598 (60.695)\n",
      "Epoch: [2][500/3057]\tLoss 0.9687 (0.9499)\tAccuracy 59.570 (60.702)\n",
      "Epoch: [2][600/3057]\tLoss 0.9796 (0.9502)\tAccuracy 58.398 (60.705)\n",
      "Epoch: [2][700/3057]\tLoss 0.9647 (0.9504)\tAccuracy 60.449 (60.679)\n",
      "Epoch: [2][800/3057]\tLoss 0.9522 (0.9506)\tAccuracy 59.375 (60.675)\n",
      "Epoch: [2][900/3057]\tLoss 0.9430 (0.9500)\tAccuracy 62.402 (60.703)\n",
      "Epoch: [2][1000/3057]\tLoss 0.9767 (0.9500)\tAccuracy 58.301 (60.698)\n",
      "Epoch: [2][1100/3057]\tLoss 0.9738 (0.9499)\tAccuracy 60.840 (60.700)\n",
      "Epoch: [2][1200/3057]\tLoss 0.9044 (0.9501)\tAccuracy 61.719 (60.670)\n",
      "Epoch: [2][1300/3057]\tLoss 0.9572 (0.9499)\tAccuracy 60.742 (60.684)\n",
      "Epoch: [2][1400/3057]\tLoss 0.9234 (0.9497)\tAccuracy 61.230 (60.685)\n",
      "Epoch: [2][1500/3057]\tLoss 0.9857 (0.9497)\tAccuracy 57.520 (60.687)\n",
      "Epoch: [2][1600/3057]\tLoss 0.9290 (0.9494)\tAccuracy 61.816 (60.693)\n",
      "Epoch: [2][1700/3057]\tLoss 0.9708 (0.9494)\tAccuracy 59.668 (60.693)\n",
      "Epoch: [2][1800/3057]\tLoss 0.9427 (0.9493)\tAccuracy 60.156 (60.702)\n",
      "Epoch: [2][1900/3057]\tLoss 0.9451 (0.9492)\tAccuracy 60.547 (60.715)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VYASRA~1\\AppData\\Local\\Temp/ipykernel_48680/3081133315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# train for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'current lr {:.5e}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# evaluate on validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VYASRA~1\\AppData\\Local\\Temp/ipykernel_48680/1248632633.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch, device, print_freq)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VYASRA~1\\AppData\\Local\\Temp/ipykernel_48680/2631350436.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m         )\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VYASRA~1\\AppData\\Local\\Temp/ipykernel_48680/2631350436.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m         )\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         )\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vyas raina\\documents\\university\\work\\phd\\research\\software\\shifted_tabular_compare\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m     return torch.batch_norm(\n\u001b[1;32m-> 2282\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m     )\n\u001b[0;32m   2284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # train for one epoch\n",
    "    print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "    train(train_dl, model, criterion, optimizer, epoch, device)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    eval(dev_in_dl, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FTTransformer",
   "language": "python",
   "name": "fttransformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
